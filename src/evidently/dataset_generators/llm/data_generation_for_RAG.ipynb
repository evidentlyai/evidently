{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "697ef555-f62c-424f-90da-bec9fbdace28",
   "metadata": {},
   "source": [
    "## Extra Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf4855a8-0d91-4d88-8fa2-05d2eb2ddbad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting chromadb\n",
      "  Obtaining dependency information for chromadb from https://files.pythonhosted.org/packages/43/cd/a875ed1f61365c9fdb46ee2de0cbea1735a9575ff718886f7eb218d4ef45/chromadb-0.5.12-py3-none-any.whl.metadata\n",
      "  Downloading chromadb-0.5.12-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting build>=1.0.3 (from chromadb)\n",
      "  Obtaining dependency information for build>=1.0.3 from https://files.pythonhosted.org/packages/84/c2/80633736cd183ee4a62107413def345f7e6e3c01563dbca1417363cf957e/build-1.2.2.post1-py3-none-any.whl.metadata\n",
      "  Downloading build-1.2.2.post1-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: pydantic>=1.9 in /opt/homebrew/Caskroom/miniconda/base/envs/py11/lib/python3.11/site-packages (from chromadb) (1.10.14)\n",
      "Collecting chroma-hnswlib==0.7.6 (from chromadb)\n",
      "  Obtaining dependency information for chroma-hnswlib==0.7.6 from https://files.pythonhosted.org/packages/0d/19/aa6f2139f1ff7ad23a690ebf2a511b2594ab359915d7979f76f3213e46c4/chroma_hnswlib-0.7.6-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading chroma_hnswlib-0.7.6-cp311-cp311-macosx_11_0_arm64.whl.metadata (252 bytes)\n",
      "Requirement already satisfied: fastapi>=0.95.2 in /opt/homebrew/Caskroom/miniconda/base/envs/py11/lib/python3.11/site-packages (from chromadb) (0.104.1)\n",
      "Requirement already satisfied: uvicorn[standard]>=0.18.3 in /opt/homebrew/Caskroom/miniconda/base/envs/py11/lib/python3.11/site-packages (from chromadb) (0.23.2)\n",
      "Requirement already satisfied: numpy>=1.22.5 in /opt/homebrew/Caskroom/miniconda/base/envs/py11/lib/python3.11/site-packages (from chromadb) (1.26.2)\n",
      "Collecting posthog>=2.4.0 (from chromadb)\n",
      "  Obtaining dependency information for posthog>=2.4.0 from https://files.pythonhosted.org/packages/c2/11/a8d4283b324cda992fbb72611c46c5c68f87902a10383dba1bde91660cc6/posthog-3.7.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading posthog-3.7.0-py2.py3-none-any.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /opt/homebrew/Caskroom/miniconda/base/envs/py11/lib/python3.11/site-packages (from chromadb) (4.8.0)\n",
      "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
      "  Obtaining dependency information for onnxruntime>=1.14.1 from https://files.pythonhosted.org/packages/f0/ff/77bee5df55f034ee81d2e1bc58b2b8511b9c54f06ce6566cb562c5d95aa5/onnxruntime-1.19.2-cp311-cp311-macosx_11_0_universal2.whl.metadata\n",
      "  Downloading onnxruntime-1.19.2-cp311-cp311-macosx_11_0_universal2.whl.metadata (4.5 kB)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in /opt/homebrew/Caskroom/miniconda/base/envs/py11/lib/python3.11/site-packages (from chromadb) (1.25.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /opt/homebrew/Caskroom/miniconda/base/envs/py11/lib/python3.11/site-packages (from chromadb) (1.25.0)\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n",
      "  Obtaining dependency information for opentelemetry-instrumentation-fastapi>=0.41b0 from https://files.pythonhosted.org/packages/ee/50/745ab075a3041b7a5f29a579d2c28eaad54f64b4589d8f9fd364c62cf0f3/opentelemetry_instrumentation_fastapi-0.48b0-py3-none-any.whl.metadata\n",
      "  Downloading opentelemetry_instrumentation_fastapi-0.48b0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /opt/homebrew/Caskroom/miniconda/base/envs/py11/lib/python3.11/site-packages (from chromadb) (1.25.0)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in /opt/homebrew/Caskroom/miniconda/base/envs/py11/lib/python3.11/site-packages (from chromadb) (0.15.2)\n",
      "Collecting pypika>=0.48.9 (from chromadb)\n",
      "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.65.0 in /opt/homebrew/Caskroom/miniconda/base/envs/py11/lib/python3.11/site-packages (from chromadb) (4.66.1)\n",
      "Requirement already satisfied: overrides>=7.3.1 in /opt/homebrew/Caskroom/miniconda/base/envs/py11/lib/python3.11/site-packages (from chromadb) (7.4.0)\n",
      "Requirement already satisfied: importlib-resources in /opt/homebrew/Caskroom/miniconda/base/envs/py11/lib/python3.11/site-packages (from chromadb) (6.1.3)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in /opt/homebrew/Caskroom/miniconda/base/envs/py11/lib/python3.11/site-packages (from chromadb) (1.65.0)\n",
      "Collecting bcrypt>=4.0.1 (from chromadb)\n",
      "  Obtaining dependency information for bcrypt>=4.0.1 from https://files.pythonhosted.org/packages/96/86/8c6a84daed4dd878fbab094400c9174c43d9b838ace077a2f8ee8bc3ae12/bcrypt-4.2.0-cp39-abi3-macosx_10_12_universal2.whl.metadata\n",
      "  Downloading bcrypt-4.2.0-cp39-abi3-macosx_10_12_universal2.whl.metadata (9.6 kB)\n",
      "Requirement already satisfied: typer>=0.9.0 in /opt/homebrew/Caskroom/miniconda/base/envs/py11/lib/python3.11/site-packages (from chromadb) (0.12.3)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in /opt/homebrew/Caskroom/miniconda/base/envs/py11/lib/python3.11/site-packages (from chromadb) (29.0.0)\n",
      "Collecting tenacity>=8.2.3 (from chromadb)\n",
      "  Obtaining dependency information for tenacity>=8.2.3 from https://files.pythonhosted.org/packages/b6/cb/b86984bed139586d01532a587464b5805f12e397594f19f931c4c2fbfa61/tenacity-9.0.0-py3-none-any.whl.metadata\n",
      "  Downloading tenacity-9.0.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: PyYAML>=6.0.0 in /opt/homebrew/Caskroom/miniconda/base/envs/py11/lib/python3.11/site-packages (from chromadb) (6.0.1)\n",
      "Collecting mmh3>=4.0.1 (from chromadb)\n",
      "  Obtaining dependency information for mmh3>=4.0.1 from https://files.pythonhosted.org/packages/13/f0/2d3daca276a4673f82af859e4b0b18befd4e6e54f1017ba48ea9735b2f1b/mmh3-5.0.1-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading mmh3-5.0.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: orjson>=3.9.12 in /opt/homebrew/Caskroom/miniconda/base/envs/py11/lib/python3.11/site-packages (from chromadb) (3.10.1)\n",
      "Collecting httpx>=0.27.0 (from chromadb)\n",
      "  Obtaining dependency information for httpx>=0.27.0 from https://files.pythonhosted.org/packages/56/95/9377bcb415797e44274b51d46e3249eba641711cf3348050f76ee7b15ffc/httpx-0.27.2-py3-none-any.whl.metadata\n",
      "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: rich>=10.11.0 in /opt/homebrew/Caskroom/miniconda/base/envs/py11/lib/python3.11/site-packages (from chromadb) (13.5.2)\n",
      "Requirement already satisfied: packaging>=19.1 in /opt/homebrew/Caskroom/miniconda/base/envs/py11/lib/python3.11/site-packages (from build>=1.0.3->chromadb) (23.1)\n",
      "Collecting pyproject_hooks (from build>=1.0.3->chromadb)\n",
      "  Obtaining dependency information for pyproject_hooks from https://files.pythonhosted.org/packages/bd/24/12818598c362d7f300f18e74db45963dbcb85150324092410c8b49405e42/pyproject_hooks-1.2.0-py3-none-any.whl.metadata\n",
      "  Downloading pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: anyio<4.0.0,>=3.7.1 in /opt/homebrew/Caskroom/miniconda/base/envs/py11/lib/python3.11/site-packages (from fastapi>=0.95.2->chromadb) (3.7.1)\n",
      "Requirement already satisfied: starlette<0.28.0,>=0.27.0 in /opt/homebrew/Caskroom/miniconda/base/envs/py11/lib/python3.11/site-packages (from fastapi>=0.95.2->chromadb) (0.27.0)\n",
      "Requirement already satisfied: certifi in /opt/homebrew/Caskroom/miniconda/base/envs/py11/lib/python3.11/site-packages (from httpx>=0.27.0->chromadb) (2024.7.4)\n",
      "Collecting httpcore==1.* (from httpx>=0.27.0->chromadb)\n",
      "  Obtaining dependency information for httpcore==1.* from https://files.pythonhosted.org/packages/06/89/b161908e2f51be56568184aeb4a880fd287178d176fd1c860d2217f41106/httpcore-1.0.6-py3-none-any.whl.metadata\n",
      "  Downloading httpcore-1.0.6-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: idna in /opt/homebrew/Caskroom/miniconda/base/envs/py11/lib/python3.11/site-packages (from httpx>=0.27.0->chromadb) (3.4)\n",
      "Requirement already satisfied: sniffio in /opt/homebrew/Caskroom/miniconda/base/envs/py11/lib/python3.11/site-packages (from httpx>=0.27.0->chromadb) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/homebrew/Caskroom/miniconda/base/envs/py11/lib/python3.11/site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/homebrew/Caskroom/miniconda/base/envs/py11/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /opt/homebrew/Caskroom/miniconda/base/envs/py11/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in /opt/homebrew/Caskroom/miniconda/base/envs/py11/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (2.25.1)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /opt/homebrew/Caskroom/miniconda/base/envs/py11/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (1.6.1)\n",
      "Requirement already satisfied: requests in /opt/homebrew/Caskroom/miniconda/base/envs/py11/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (2.32.1)\n",
      "Requirement already satisfied: requests-oauthlib in /opt/homebrew/Caskroom/miniconda/base/envs/py11/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (1.3.1)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in /opt/homebrew/Caskroom/miniconda/base/envs/py11/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in /opt/homebrew/Caskroom/miniconda/base/envs/py11/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (2.0.4)\n",
      "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
      "  Obtaining dependency information for coloredlogs from https://files.pythonhosted.org/packages/a7/06/3d6badcf13db419e25b07041d9c7b4a2c331d3f4e7134445ec5df57714cd/coloredlogs-15.0.1-py2.py3-none-any.whl.metadata\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting flatbuffers (from onnxruntime>=1.14.1->chromadb)\n",
      "  Obtaining dependency information for flatbuffers from https://files.pythonhosted.org/packages/41/f0/7e988a019bc54b2dbd0ad4182ef2d53488bb02e58694cd79d61369e85900/flatbuffers-24.3.25-py2.py3-none-any.whl.metadata\n",
      "  Downloading flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Requirement already satisfied: protobuf in /opt/homebrew/Caskroom/miniconda/base/envs/py11/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb) (4.25.1)\n",
      "Requirement already satisfied: sympy in /opt/homebrew/Caskroom/miniconda/base/envs/py11/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb) (1.12)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /opt/homebrew/Caskroom/miniconda/base/envs/py11/lib/python3.11/site-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.14)\n",
      "Requirement already satisfied: importlib-metadata<=7.1,>=6.0 in /opt/homebrew/Caskroom/miniconda/base/envs/py11/lib/python3.11/site-packages (from opentelemetry-api>=1.2.0->chromadb) (6.8.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /opt/homebrew/Caskroom/miniconda/base/envs/py11/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.61.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.25.0 in /opt/homebrew/Caskroom/miniconda/base/envs/py11/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.25.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.25.0 in /opt/homebrew/Caskroom/miniconda/base/envs/py11/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.25.0)\n",
      "Collecting opentelemetry-instrumentation-asgi==0.48b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Obtaining dependency information for opentelemetry-instrumentation-asgi==0.48b0 from https://files.pythonhosted.org/packages/db/74/a0e0d38622856597dd8e630f2bd793760485eb165708e11b8be1696bbb5a/opentelemetry_instrumentation_asgi-0.48b0-py3-none-any.whl.metadata\n",
      "  Downloading opentelemetry_instrumentation_asgi-0.48b0-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting opentelemetry-instrumentation==0.48b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Obtaining dependency information for opentelemetry-instrumentation==0.48b0 from https://files.pythonhosted.org/packages/0a/7f/405c41d4f359121376c9d5117dcf68149b8122d3f6c718996d037bd4d800/opentelemetry_instrumentation-0.48b0-py3-none-any.whl.metadata\n",
      "  Downloading opentelemetry_instrumentation-0.48b0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.48b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Obtaining dependency information for opentelemetry-semantic-conventions==0.48b0 from https://files.pythonhosted.org/packages/b7/7a/4f0063dbb0b6c971568291a8bc19a4ca70d3c185db2d956230dd67429dfc/opentelemetry_semantic_conventions-0.48b0-py3-none-any.whl.metadata\n",
      "  Downloading opentelemetry_semantic_conventions-0.48b0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-util-http==0.48b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Obtaining dependency information for opentelemetry-util-http==0.48b0 from https://files.pythonhosted.org/packages/ad/2e/36097c0a4d0115b8c7e377c90bab7783ac183bc5cb4071308f8959454311/opentelemetry_util_http-0.48b0-py3-none-any.whl.metadata\n",
      "  Downloading opentelemetry_util_http-0.48b0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: setuptools>=16.0 in /opt/homebrew/Caskroom/miniconda/base/envs/py11/lib/python3.11/site-packages (from opentelemetry-instrumentation==0.48b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (65.5.1)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /opt/homebrew/Caskroom/miniconda/base/envs/py11/lib/python3.11/site-packages (from opentelemetry-instrumentation==0.48b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.16.0)\n",
      "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.48b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Obtaining dependency information for asgiref~=3.0 from https://files.pythonhosted.org/packages/39/e3/893e8757be2612e6c266d9bb58ad2e3651524b5b40cf56761e985a28b13e/asgiref-3.8.1-py3-none-any.whl.metadata\n",
      "  Downloading asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromadb)\n",
      "  Obtaining dependency information for opentelemetry-api>=1.2.0 from https://files.pythonhosted.org/packages/fb/1f/737dcdbc9fea2fa96c1b392ae47275165a7c641663fbb08a8d252968eed2/opentelemetry_api-1.27.0-py3-none-any.whl.metadata\n",
      "  Downloading opentelemetry_api-1.27.0-py3-none-any.whl.metadata (1.4 kB)\n",
      "INFO: pip is looking at multiple versions of opentelemetry-sdk to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n",
      "  Obtaining dependency information for opentelemetry-instrumentation-fastapi>=0.41b0 from https://files.pythonhosted.org/packages/a5/29/a97842d6dfa679bf0f3624ce1ea3458eb185befd536cafe580daa9ab68ae/opentelemetry_instrumentation_fastapi-0.47b0-py3-none-any.whl.metadata\n",
      "  Downloading opentelemetry_instrumentation_fastapi-0.47b0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting opentelemetry-instrumentation-asgi==0.47b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Obtaining dependency information for opentelemetry-instrumentation-asgi==0.47b0 from https://files.pythonhosted.org/packages/ba/d9/c74cb6d69589cc97d856cb3f427dfcef37ec16f9564586290c9c075d9020/opentelemetry_instrumentation_asgi-0.47b0-py3-none-any.whl.metadata\n",
      "  Downloading opentelemetry_instrumentation_asgi-0.47b0-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting opentelemetry-instrumentation==0.47b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Obtaining dependency information for opentelemetry-instrumentation==0.47b0 from https://files.pythonhosted.org/packages/1f/6a/be31a84ddd13e9018fcca6885e4710f227eb0fd06eda1896da67287faa2e/opentelemetry_instrumentation-0.47b0-py3-none-any.whl.metadata\n",
      "  Downloading opentelemetry_instrumentation-0.47b0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.47b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Obtaining dependency information for opentelemetry-semantic-conventions==0.47b0 from https://files.pythonhosted.org/packages/00/c2/ca5cef8e4cd8eec5a95deed95ec3f6005e499fd9d17ca08731ced03a6921/opentelemetry_semantic_conventions-0.47b0-py3-none-any.whl.metadata\n",
      "  Downloading opentelemetry_semantic_conventions-0.47b0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-util-http==0.47b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Obtaining dependency information for opentelemetry-util-http==0.47b0 from https://files.pythonhosted.org/packages/10/7e/98749e14a4e3f4db8bc016e6b42aba40e4d934baeb8767b8658a99d0dfac/opentelemetry_util_http-0.47b0-py3-none-any.whl.metadata\n",
      "  Downloading opentelemetry_util_http-0.47b0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromadb)\n",
      "  Obtaining dependency information for opentelemetry-api>=1.2.0 from https://files.pythonhosted.org/packages/e3/a7/6322d1d7a1fb926e8b99208c27730f21217da2f1e0e11dab48a78a0427a4/opentelemetry_api-1.26.0-py3-none-any.whl.metadata\n",
      "  Downloading opentelemetry_api-1.26.0-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n",
      "  Obtaining dependency information for opentelemetry-instrumentation-fastapi>=0.41b0 from https://files.pythonhosted.org/packages/b8/96/905d575947342c4fd6781a28f6d7bc7f4f6670d45e3b1a85f8a06955c9ae/opentelemetry_instrumentation_fastapi-0.46b0-py3-none-any.whl.metadata\n",
      "  Downloading opentelemetry_instrumentation_fastapi-0.46b0-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting opentelemetry-instrumentation-asgi==0.46b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Obtaining dependency information for opentelemetry-instrumentation-asgi==0.46b0 from https://files.pythonhosted.org/packages/47/8d/8955c7fbd949e3ea1c186c7422047f675bf4f7c8976afd2fdf713183318e/opentelemetry_instrumentation_asgi-0.46b0-py3-none-any.whl.metadata\n",
      "  Downloading opentelemetry_instrumentation_asgi-0.46b0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting opentelemetry-instrumentation==0.46b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Obtaining dependency information for opentelemetry-instrumentation==0.46b0 from https://files.pythonhosted.org/packages/10/e5/d6fff0a6f6fbddf03c7fb48ab47925581c4f1a8268f9ad98e5ea4a8b90a5/opentelemetry_instrumentation-0.46b0-py3-none-any.whl.metadata\n",
      "  Downloading opentelemetry_instrumentation-0.46b0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.46b0 in /opt/homebrew/Caskroom/miniconda/base/envs/py11/lib/python3.11/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.46b0)\n",
      "Collecting opentelemetry-util-http==0.46b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Obtaining dependency information for opentelemetry-util-http==0.46b0 from https://files.pythonhosted.org/packages/a2/7f/26d3d8880ea79adde8bb7bc306b25ca5134d6f6c3006ba464716405b4729/opentelemetry_util_http-0.46b0-py3-none-any.whl.metadata\n",
      "  Downloading opentelemetry_util_http-0.46b0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb)\n",
      "  Obtaining dependency information for monotonic>=1.5 from https://files.pythonhosted.org/packages/9a/67/7e8406a29b6c45be7af7740456f7f37025f0506ae2e05fb9009a53946860/monotonic-1.6-py2.py3-none-any.whl.metadata\n",
      "  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb)\n",
      "  Obtaining dependency information for backoff>=1.10.0 from https://files.pythonhosted.org/packages/df/73/b6e24bd22e6720ca8ee9a85a0c4a2971af8497d8f3193fa05390cbd46e09/backoff-2.2.1-py3-none-any.whl.metadata\n",
      "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/homebrew/Caskroom/miniconda/base/envs/py11/lib/python3.11/site-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/homebrew/Caskroom/miniconda/base/envs/py11/lib/python3.11/site-packages (from rich>=10.11.0->chromadb) (2.16.1)\n",
      "Requirement already satisfied: huggingface_hub<1.0,>=0.16.4 in /opt/homebrew/Caskroom/miniconda/base/envs/py11/lib/python3.11/site-packages (from tokenizers>=0.13.2->chromadb) (0.22.2)\n",
      "Requirement already satisfied: click>=8.0.0 in /opt/homebrew/Caskroom/miniconda/base/envs/py11/lib/python3.11/site-packages (from typer>=0.9.0->chromadb) (8.1.6)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /opt/homebrew/Caskroom/miniconda/base/envs/py11/lib/python3.11/site-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
      "Requirement already satisfied: httptools>=0.5.0 in /opt/homebrew/Caskroom/miniconda/base/envs/py11/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.1)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in /opt/homebrew/Caskroom/miniconda/base/envs/py11/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.1)\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /opt/homebrew/Caskroom/miniconda/base/envs/py11/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.19.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /opt/homebrew/Caskroom/miniconda/base/envs/py11/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n",
      "Requirement already satisfied: websockets>=10.4 in /opt/homebrew/Caskroom/miniconda/base/envs/py11/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (12.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/homebrew/Caskroom/miniconda/base/envs/py11/lib/python3.11/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/homebrew/Caskroom/miniconda/base/envs/py11/lib/python3.11/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/homebrew/Caskroom/miniconda/base/envs/py11/lib/python3.11/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
      "Requirement already satisfied: filelock in /opt/homebrew/Caskroom/miniconda/base/envs/py11/lib/python3.11/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/homebrew/Caskroom/miniconda/base/envs/py11/lib/python3.11/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2024.9.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/homebrew/Caskroom/miniconda/base/envs/py11/lib/python3.11/site-packages (from importlib-metadata<=7.1,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.16.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/homebrew/Caskroom/miniconda/base/envs/py11/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/Caskroom/miniconda/base/envs/py11/lib/python3.11/site-packages (from requests->kubernetes>=28.1.0->chromadb) (3.2.0)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
      "  Obtaining dependency information for humanfriendly>=9.1 from https://files.pythonhosted.org/packages/f0/0f/310fb31e39e2d734ccaa2c0fb981ee41f7bd5056ce9bc29b2248bd569169/humanfriendly-10.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/homebrew/Caskroom/miniconda/base/envs/py11/lib/python3.11/site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/homebrew/Caskroom/miniconda/base/envs/py11/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.5.1)\n",
      "Downloading chromadb-0.5.12-py3-none-any.whl (602 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m602.6/602.6 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading chroma_hnswlib-0.7.6-cp311-cp311-macosx_11_0_arm64.whl (185 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m185.0/185.0 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading bcrypt-4.2.0-cp39-abi3-macosx_10_12_universal2.whl (472 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m472.4/472.4 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hDownloading build-1.2.2.post1-py3-none-any.whl (22 kB)\n",
      "Downloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading httpcore-1.0.6-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.0/78.0 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mmh3-5.0.1-cp311-cp311-macosx_11_0_arm64.whl (38 kB)\n",
      "Downloading onnxruntime-1.19.2-cp311-cp311-macosx_11_0_universal2.whl (16.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_instrumentation_fastapi-0.46b0-py3-none-any.whl (11 kB)\n",
      "Downloading opentelemetry_instrumentation-0.46b0-py3-none-any.whl (29 kB)\n",
      "Downloading opentelemetry_instrumentation_asgi-0.46b0-py3-none-any.whl (14 kB)\n",
      "Downloading opentelemetry_util_http-0.46b0-py3-none-any.whl (6.9 kB)\n",
      "Downloading posthog-3.7.0-py2.py3-none-any.whl (54 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.4/54.4 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tenacity-9.0.0-py3-none-any.whl (28 kB)\n",
      "Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
      "Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Downloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
      "Downloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
      "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: pypika\n",
      "  Building wheel for pypika (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53723 sha256=8643461882832391b1d76edba76a526166c2d9df66a46f567985fb53216f60b6\n",
      "  Stored in directory: /Users/emelidral/Library/Caches/pip/wheels/a3/01/bd/4c40ceb9d5354160cb186dcc153360f4ab7eb23e2b24daf96d\n",
      "Successfully built pypika\n",
      "Installing collected packages: pypika, monotonic, flatbuffers, tenacity, pyproject_hooks, opentelemetry-util-http, mmh3, humanfriendly, httpcore, chroma-hnswlib, bcrypt, backoff, asgiref, posthog, httpx, coloredlogs, build, opentelemetry-instrumentation, onnxruntime, opentelemetry-instrumentation-asgi, opentelemetry-instrumentation-fastapi, chromadb\n",
      "  Attempting uninstall: tenacity\n",
      "    Found existing installation: tenacity 8.2.2\n",
      "    Uninstalling tenacity-8.2.2:\n",
      "      Successfully uninstalled tenacity-8.2.2\n",
      "  Attempting uninstall: httpcore\n",
      "    Found existing installation: httpcore 0.17.3\n",
      "    Uninstalling httpcore-0.17.3:\n",
      "      Successfully uninstalled httpcore-0.17.3\n",
      "  Attempting uninstall: httpx\n",
      "    Found existing installation: httpx 0.24.1\n",
      "    Uninstalling httpx-0.24.1:\n",
      "      Successfully uninstalled httpx-0.24.1\n",
      "Successfully installed asgiref-3.8.1 backoff-2.2.1 bcrypt-4.2.0 build-1.2.2.post1 chroma-hnswlib-0.7.6 chromadb-0.5.12 coloredlogs-15.0.1 flatbuffers-24.3.25 httpcore-1.0.6 httpx-0.27.2 humanfriendly-10.0 mmh3-5.0.1 monotonic-1.6 onnxruntime-1.19.2 opentelemetry-instrumentation-0.46b0 opentelemetry-instrumentation-asgi-0.46b0 opentelemetry-instrumentation-fastapi-0.46b0 opentelemetry-util-http-0.46b0 posthog-3.7.0 pypika-0.48.9 pyproject_hooks-1.2.0 tenacity-9.0.0\n"
     ]
    }
   ],
   "source": [
    "! pip install chromadb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b8aec3-e00e-4919-b2a8-b19722311261",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "547c43f3-e58f-450c-b80b-c396eb2655a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai \n",
    "from openai import OpenAI\n",
    "import pprint\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import chromadb\n",
    "from chromadb.utils import embedding_functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6fac99-e1db-48be-9554-88ecddac271e",
   "metadata": {},
   "source": [
    "## Chunked data collection setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9b93b470-9d32-4757-9d03-915992e2a7c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection db_collection created successfully\n",
      "{'data': None,\n",
      " 'documents': [],\n",
      " 'embeddings': None,\n",
      " 'ids': [],\n",
      " 'included': ['metadatas', 'documents'],\n",
      " 'metadatas': [],\n",
      " 'uris': None}\n"
     ]
    }
   ],
   "source": [
    "collection_name = \"db_collection\"\n",
    "default_embedding_function = embedding_functions.SentenceTransformerEmbeddingFunction(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "chroma_client = chromadb.PersistentClient(path=\"./chromadb/\")\n",
    "# declare ChromaDB collection\n",
    "collection = chroma_client.get_or_create_collection(\n",
    "    name=collection_name,\n",
    "    embedding_function=default_embedding_function\n",
    "    )\n",
    "\n",
    "result = collection.get()\n",
    "\n",
    "print(f\"Collection {collection_name} created successfully\")\n",
    "pprint.pprint(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d547021f-9d4d-42cf-b580-abc6a1008cd1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def load_md_from_dir(dir_path):\n",
    "    \"\"\"\n",
    "    Loads Markdown (.md) files from the specified directory.\n",
    "\n",
    "    Args:\n",
    "        dir_path (str): Path to the directory containing .md files.\n",
    "\n",
    "    Returns:\n",
    "        List[dict]: A list of dictionaries with the text content of each .md file.\n",
    "    \"\"\"\n",
    "    md_files = [\n",
    "        os.path.join(dir_path, filename) \n",
    "        for filename in os.listdir(dir_path) \n",
    "        if filename.endswith(\".md\")\n",
    "    ]\n",
    "    \n",
    "    documents = []\n",
    "    for file_path in md_files:\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            documents.append({\"text\": file.read()})\n",
    "    \n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "53f147f1-f8a2-4095-a840-2bacbc0aaf63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text(text, chunk_size=100, chunk_overlap=20):\n",
    "    \"\"\"\n",
    "    Splits the input text into overlapping chunks.\n",
    "\n",
    "    Args:\n",
    "        text (str): The text to split.\n",
    "        chunk_size (int): The size of each chunk. Default is 100.\n",
    "        chunk_overlap (int): The number of overlapping characters between chunks. Default is 20.\n",
    "\n",
    "    Returns:\n",
    "        List[str]: A list of text chunks.\n",
    "    \"\"\"\n",
    "    chunks = []\n",
    "    text_length = len(text)\n",
    "    \n",
    "    for start in range(0, text_length, chunk_size - chunk_overlap):\n",
    "        end = min(start + chunk_size, text_length)\n",
    "        chunks.append(text[start:end])\n",
    "    \n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c0c9c8e2-0f2f-4fe0-aeee-68b0bb67cea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 4 files loaded\n",
      "Split in to 270 chunks\n"
     ]
    }
   ],
   "source": [
    "directory_path = \"./evidently_reference/\"\n",
    "\n",
    "# load documents from directory\n",
    "md_files = load_md_from_dir(directory_path)\n",
    "\n",
    "print(f\" {len(md_files)} files loaded\")\n",
    "\n",
    "# Split text into chunks\n",
    "chunked_files = [\n",
    "    {\n",
    "        'id': f\"{file_id}-{chunk_id}\",\n",
    "        'text': chunk,\n",
    "    }\n",
    "    for file_id, file in enumerate(md_files)\n",
    "    for chunk_id, chunk in enumerate(split_text(file[\"text\"], chunk_size=500, chunk_overlap=50))\n",
    "]\n",
    "\n",
    "print(f\"Split in to {len(chunked_files)} chunks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7bf99fde-8aa7-4111-ad7e-eec59bd0c23e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection db_collection has 270 documents\n"
     ]
    }
   ],
   "source": [
    "# insert documents with embeddings to collection ChromaDB\n",
    "for chunk in chunked_files:\n",
    "    collection.upsert(\n",
    "            ids=chunk['id'],\n",
    "            documents=chunk['text'],\n",
    "    )\n",
    "\n",
    "result = collection.get()\n",
    "\n",
    "print(f\"Collection {collection_name} has {len(result['ids'])} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "50ec8822-e2dc-4a01-bad3-44f1f123ed5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "#Just incase we need to delete collection\n",
    "#list_collections = chroma_client.list_collections()\n",
    "#print(list_collections)\n",
    "\n",
    "chroma_client.delete_collection(collection_name)\n",
    "list_collections = chroma_client.list_collections()\n",
    "print(list_collections)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebaf34e6-d454-4d38-b08a-f57550b39e74",
   "metadata": {},
   "source": [
    "## Dataset Generation chain of promts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ced14436-c4b3-4b25-8cc7-7cdb112eed66",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "client = OpenAI(\n",
    "    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b0cf1e-5356-44e4-855b-5169a21260e2",
   "metadata": {},
   "source": [
    "### Get a seed query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe13a2c7-1c76-4d18-8bde-d1821078822f",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_query = \"How do I get Evidently data drift report for my data?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "d81f6108-79ef-4148-bc8e-b1050cc1637f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ods](../customization/options-for-statistical-tests.md).\\n{% endhint %}\\n\\n## Text Data \\n\\n![](../.gitbook/assets/reports/metric_column_drift_text-min.png)\\n\\nText content drift using a **domain classifier**. Evidently trains a binary classification model to discriminate between data from reference and current distributions. \\n\\nThe default for **small data with <= 1000 observations** detects drift if the ROC AUC of the drift detection classifier > possible ROC AUC of the random classifier at a 95th per',\n",
       " 'score and compares it to the reference or against a defined condition. | **Required**:<br>N/A<br><br> **Optional**:<ul><li>`threshold_probas`(default for classification = None; default for probabilistic classification = 0.5)</li><li>`k`</li></ul> **Test conditions**: <ul><li>*standard parameters*</li></ul>| Expects +/-20% or better than a dummy model.<br><br>**With reference**: if the F1 is over 20% higher or lower, the test fails.<br><br>**No reference**: if the F1 is lower than the F1 of the d',\n",
       " '><li> Checks if the text begins with a specified combination. </li><li> Returns True/False for every input.</li></ul> Example use:<br> `BeginsWith(prefix=\"How\")`| **Required:**<br>`prefix`<br><br>**Optional:**<ul><li>`display_name`</li><li>`case_sensitive = True` or `False`</li></ul> |\\n| **EndsWith()** <ul><li> Checks if the text ends with a specified combination. </li><li> Returns True/False for every input. </li></ul> Example use:<br> `EndsWith(suffix=\"Thank you.\")`| **Required:**<br>`suffix`<',\n",
       " 'ositive Rate)</li><li>TNR (True Negative Rate)</li><li>FPR (False Positive Rate)</li><li>FNR (False Negative Rate)</li><li>ROC AUC Score (for probabilistic classification)</li><li>LogLoss (for probabilistic classification) </li></ul> | **Required:**:<br>n/a<br><br>**Optional:**<ul><li>`probas_threshold` (default for classification = None; default for probabilistic classification = 0.5)</li><li>`k` (default = None)</li></ul> |\\n| **ClassificationClassBalance()** <br><br> Calculates the number of o',\n",
       " 'columns contain empty or infinite values (+-np.inf), these values will be filtered out when calculating distribution drift in the corresponding column.\\n\\nBy default, drift tests do not react to changes or increases in the number of empty values. Since the high number of nulls can be an important indicator, we recommend grouping the data drift tests (that check for distribution shift) with data integrity tests (that check for a share of nulls). You can choose from several null-related [tests](all-',\n",
       " '. Prediction and target are required. Input features are optional.\\n\\n**Composition**:\\n* `RegressionQualityMetric()`\\n* `RegressionPredictedVsActualScatter()`\\n* `RegressionPredictedVsActualPlot()`\\n* `RegressionErrorPlot()`\\n* `RegressionAbsPercentageErrorPlot()`\\n* `RegressionErrorDistribution()`\\n* `RegressionErrorNormality()`\\n* `RegressionTopErrorMetric()`\\n* `RegressionErrorBiasTable()` for all or specified `columns`\\n\\n**Optional parameters**:\\n* `columns`\\n\\n</details>\\n\\n<details>\\n  \\n<summary>Classifica',\n",
       " 'ders items that are present in training. \\n\\nFurther reading: [Castells, P., Vargas, S., & Wang, J. (2011). Novelty and Diversity Metrics for Recommender Systems: Choice, Discovery and Relevance](https://repositorio.uam.es/bitstream/handle/10486/666094/novelty_castells_DDR_2011.pdf)\\n\\n# Serendipity\\n\\n![](../.gitbook/assets/reports/metric_serendipity-min.png)\\n\\n**Evidently Metric**: `SerendipityMetric`\\n\\nRecommendation serendipity: this metric measures how unusual the relevant recommendations are in K,',\n",
       " 'ems in positions 1, 2, and 10 are relevant, the formula will look as:\\n\\n$$\\nAP@10 = \\\\frac{Precision@1+Precision@2+Precision@10}{3}\\n$$\\n\\n* **Compute Mean Average Precision (MAP) at K**. Average the results across all users (or queries) in the dataset.\\n\\n$$\\n\\\\text{MAP@K} = \\\\frac{1}{U} \\\\sum_{u=1}^{U} \\\\text{AP@K}_u\\n$$\\n\\nWhere *U* is the total number of users or queries in the dataset, and *AP* is the average precision for a given list.\\n\\n**Range**: 0 to 1.\\n\\n**Interpretation**: Higher MAP at K values indica',\n",
       " 'r><br>**With reference**: the test fails if the number of columns with missing values is higher than in reference.  <br>**No reference**: the test fails if the dataset contains columns with missing values.|\\n| **TestShareOfColumnsWithMissingValues()** | Dataset-level. <br><br> Tests the share of columns that contain missing values in the dataset against the reference or a defined condition.| **Required**:<br> N/A <br><br> **Optional**: <ul><li>`missing_values = [], replace = True/False` (default ',\n",
       " 'talog.\\n\\n**Range**: 0 to 1, where 0 represents the perfect equality (recommended items are evenly distributed among users), and 1 is complete inequality (the recommendations are concentrated on a single item).\\n\\n**Interpretation**: the lower the value (usually preferable), the more equal the item distribution in recommendations. If the value is high, a few items are frequently recommended to many users while others are ignored.\\n\\nFurther reading: [Abdollahpouri, H., Mansoury, M., Burke, R., Mobashe']"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fixed size for the random list\n",
    "sample_size = 10\n",
    "\n",
    "# Generate a random list with the fixed size from the existing list\n",
    "random_chuncks = [item['text'] for item in random.sample(chunked_files, min(sample_size, len(chunked_files)))]\n",
    "random_chuncks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "90712120-3ac4-48d0-a749-9f8ef72f4247",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"You are an assisstant who generates questions based on provided context\"\n",
    "number_of_questions = 10\n",
    "user_prompt = \"\"\"\n",
    "Generate {N} conceptual questions based on the provided context and can be answered from the information in the provided context.\n",
    "Here is a context\n",
    "<context>\n",
    "    {context}\n",
    "</context>\n",
    "\n",
    "Remain faithful to the underlying context. \n",
    "Avoid providing any preamble!\n",
    "Avoid providing any closing statement!\n",
    "Please return only a list of coma separated generated questions in string format.\n",
    "\"\"\"\n",
    "\n",
    "context = \"\\n\\n\".join(random_chuncks)\n",
    "\n",
    "formated_user_prompt = user_prompt.format(context=context, N=number_of_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "7aa2632f-5bda-4395-81a2-77ccb4dd994b",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",  # Updated to a valid model\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": formated_user_prompt}\n",
    "    ],\n",
    "    max_tokens=400,  # Limits the response length\n",
    "    temperature=0.7,  # Controls randomness in the output\n",
    "    n=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "d01f1b79-7781-4e60-b6b0-71a31f860376",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_seed_queries = response.choices[0].message.content.strip().split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "4ba9d23b-b502-4e6e-9535-6c672d6ec309",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\"How does the TestShareOfColumnsWithMissingValues function determine if a dataset fails the test with reference?',\n",
       " ' What optional parameters can be included in the TestShareOfColumnsWithMissingValues function?',\n",
       " ' What is the purpose of the HuggingFaceModel function?',\n",
       " ' How does the HuggingFaceToxicityModel function detect hate speech?',\n",
       " ' What condition causes the TestNumberOfDuplicatedRows to fail without a reference?',\n",
       " ' What is measured by the TestShareOfDriftedColumns function?',\n",
       " ' What are the required and optional parameters for the ScoreDistribution function?',\n",
       " ' What is the role of the ColumnSummaryMetric in the DataQualityPreset?',\n",
       " ' How does the drift detection method choose the appropriate test for each column?',\n",
       " ' How is AP@K calculated in the context of relevant item positions?\"']"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_seed_queries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8547f2-b3a7-4058-8175-b3872f318d1a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Get alternative questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "39df8c68-84cb-43af-aba3-63d1f10537ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#do not forget to write a prompt for seed query generation\n",
    "system_prompt = \"You are a smart assistant who helps rephrase questions\" \n",
    "\n",
    "number_of_reformulations = 5\n",
    "\n",
    "seed_query = \"How do I get Evidently data drift report for my data?\"\n",
    "\n",
    "user_prompt = \"\"\"Write for me {number_of_reformulations} alternative questions quite similar to the question you got.\n",
    "The question: {seed_query}\n",
    "\n",
    "Return a list of questions.\n",
    "This should be only a list of string questions, separated by comma\n",
    "\"\"\"\n",
    "\n",
    "formated_user_prompt = user_prompt.format(number_of_reformulations=number_of_reformulations, \n",
    "                                          seed_query = generated_seed_query)\n",
    "                         #seed_query=seed_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "983b4545-0511-473e-8797-7fbdf2d5ff54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a request to the OpenAI to expand a seed question\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",  # Updated to a valid model\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": formated_user_prompt}\n",
    "    ],\n",
    "    max_tokens=400,  # Limits the response length\n",
    "    temperature=0.7,  # Controls randomness in the output\n",
    "    n=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "9c2fe61b-5470-469a-949c-9e1a65c0f4e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Completion:\n",
      "What criteria does the `TestShareOfColumnsWithMissingValues()` function use to identify failure without a reference dataset?, How does the absence of a reference affect the `TestShareOfColumnsWithMissingValues()` function's failure detection?, In what way does the `TestShareOfColumnsWithMissingValues()` function assess failure without having a reference?, How is failure determined by the `TestShareOfColumnsWithMissingValues()` function when a reference is not given?, What is the method used by the `TestShareOfColumnsWithMissingValues()` function to evaluate failure without a reference dataset?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['What criteria does the `TestShareOfColumnsWithMissingValues()` function use to identify failure without a reference dataset?',\n",
       " \" How does the absence of a reference affect the `TestShareOfColumnsWithMissingValues()` function's failure detection?\",\n",
       " ' In what way does the `TestShareOfColumnsWithMissingValues()` function assess failure without having a reference?',\n",
       " ' How is failure determined by the `TestShareOfColumnsWithMissingValues()` function when a reference is not given?',\n",
       " ' What is the method used by the `TestShareOfColumnsWithMissingValues()` function to evaluate failure without a reference dataset?']"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion_text = response.choices[0].message.content\n",
    "print(f\"Generated Completion:\\n{completion_text}\")\n",
    "\n",
    "queries = completion_text.strip().split(\",\")\n",
    "queries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df169dc5-acbd-46e7-b163-c5ebebb8ea0d",
   "metadata": {},
   "source": [
    "### Find relevant chuncks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0333932a-8f6e-48e6-9f28-9f5c0406d091",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_collection(question, n_results = 3):\n",
    "    \"\"\"\n",
    "    Queries the collection with a given question and returns the relevant text chunks.\n",
    "    \n",
    "    Args:\n",
    "        question (str): The query or question text to search for.\n",
    "        n_results (int): Number of results to retrieve. Default is 3.\n",
    "\n",
    "    Returns:\n",
    "        List[str]: A list of relevant text chunks.\n",
    "    \"\"\"\n",
    "    # Perform the query\n",
    "    results = collection.query(\n",
    "        query_texts=question,\n",
    "        n_results=n_results,\n",
    "        # include=['embeddings', 'documents', 'distances']\n",
    "    )\n",
    "\n",
    "    # Extract relevant text chunks from the documents\n",
    "    relevant_chunks = [\n",
    "        chunk for document in results[\"documents\"] for chunk in document\n",
    "    ]\n",
    "    \n",
    "    return relevant_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b827e30d-a7b2-406f-a139-5b7fdd3bab6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['how to detect drift in ML embeddings](https://www.evidentlyai.com/blog/embedding-drift-detection).  \\n\\nAdditional links:  \\n\\n* [How to interpret data and prediction drift together? ](https://evidentlyai.com/blog/data-and-prediction-drift)  \\n\\n* [Do I need to monitor data drift if I can measure the ML model quality?](https://evidentlyai.com/blog/ml-monitoring-do-i-need-data-drift)  \\n\\n* [\"My data drifted. What\\'s next?\" How to handle ML model drift in production.](https://evidentlyai.com/blog/ml-monit',\n",
       " 'arget). </li><li> Returns predicted probability for the “hate” label. </li><li> Scale: 0 to 1. </li></ul> | **Optional**: <ul><li>`toxic_label=\"hate\"` (default)</li><li> `display_name`</li></ul> |\\n\\n# Data Drift\\n\\n**Defaults for Data Drift**. By default, all data drift metrics use the Evidently [drift detection logic](data-drift-algorithm.md) that selects a drift detection method based on feature type and volume. You always need a reference dataset.\\n\\nTo modify the logic or select a different test,',\n",
       " 'alculates the number and share of drifted features in the dataset. </li><li>Each feature is tested for drift individually using the default algorithm, unless a custom approach is specified.</li></ul>| **Required:**<br>n/a<br><br>**Optional:**<ul><li>`сolumns` (default=all)</li><li>`drift_share`(default for dataset drift = 0.5)</li> <li>`stattest`</li><li>`cat_stattest`</li><li>`num_stattest`</li><li>`per_column_stattest`</li><li>`stattest_threshold`</li><li>`cat_stattest_threshold`</li><li>`num_']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_collection(seed_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "d549b9ab-1e3a-490e-a57e-669af72dbdb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#relevant_chunks = [query_collection(query) for query in queries]\n",
    "relevant_chunks = [query_collection(query) for query in generated_seed_queries]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "cfeb5073-f37c-4d24-85a7-bf2043dacb1e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['r><br>**With reference**: the test fails if the number of columns with missing values is higher than in reference.  <br>**No reference**: the test fails if the dataset contains columns with missing values.|\\n| **TestShareOfColumnsWithMissingValues()** | Dataset-level. <br><br> Tests the share of columns that contain missing values in the dataset against the reference or a defined condition.| **Required**:<br> N/A <br><br> **Optional**: <ul><li>`missing_values = [], replace = True/False` (default ',\n",
       "  '**With reference**: the test fails if the share of rows with missing values is over 10% higher than in reference. <br><br>**No reference**: the test fails if the dataset contains rows with missing values.|\\n| **TestNumberOfDifferentMissingValues()**| Dataset-level. <br><br> Tests the number of differently encoded missing values in the dataset against the reference or a defined condition. Detects 4 types of missing values by default and/or values from a user list. | **Required**:<br>N/A<br><br>**O',\n",
       "  ' test fails if the dataset contains rows with missing values.|\\n| **TestShareOfRowsWithMissingValues()** | Dataset-level. <br><br> Tests the share of rows that contain missing values against the reference or a defined condition. | **Required**:<br>N/A<br><br>**Optional**:<ul><li>`missing_values = [], replace = True/False` (default = default list)</li></ul>**Test conditions** <ul><li>*standard parameters*</li></ul>| Expects up to +10% or 0.<br><br>**With reference**: the test fails if the share of'],\n",
       " [\"the Test's defaults. You can see them in the tables below. The listed Preset parameters apply to the relevant individual Tests inside the Preset.\\n\\n<details>\\n \\n<summary>NoTargetPerformance Test Preset</summary>\\n\\nPreset name: `NoTargetPerformanceTestPreset()`\\n\\n**Composition**: \\n* `TestShareOfDriftedColumns()`\\n* `TestColumnDrift(column_name=prediction)`\\n* `TestColumnShareOfMissingValues()` for `all` or `сolumns` if provided\\n* `TestShareOfOutRangeValues()` for all numerical or specified `columns`\\n* \",\n",
       "  'lumnsType()`\\n* `TestColumnShareOfMissingValues()` for all or specified `columns`\\n* `TestShareOfOutRangeValues()` for all numerical or specified `columns`\\n* `TestShareOfOutListValues()` for all categorical or specified  `columns`\\n* `TestMeanInNSigmas()` for all numerical or specified `columns`\\n\\n**Optional parameters**: \\n* `columns`\\n\\n</details>\\n\\n<details>\\n \\n<summary>Data Quality Test Preset</summary>\\n\\nPreset name: `DataQualityTestPreset()`\\n\\n**Composition**: \\n* `TestColumnShareOfMissingValues()` fo',\n",
       "  \"**: N/A |\\n\\n## Column Values\\n\\n| Test name  | Description | Parameters | Default test conditions | \\n|---|---|---|---|\\n| **TestColumnValueMin**(column_name='num-column') | Column-level. <br><br> Tests the minimum value of a given numerical column against reference or a defined condition. |  **Required**:<ul><li>`column_name`</li></ul> **Optional:** N/A <br><br> **Test conditions**: <ul><li>*standard parameters*</li></ul> | Expects not lower.<br><br>**With reference**: the test fails if the minimum \"],\n",
       " ['tems by a chosen characteristic.\\n\\nThe visualization shows:\\n* The distribution of items in the training set for the defined `column_name` (with duplicates dropped). This represents the item catalog by this dimension. \\n* The distribution of the recommended items for the defined `column_name` in the current and reference (if available) datasets. \\n\\nThis visualization helps see the patterns in the model recommendations. In a simplified example, you might observe that the training data contains 3x com',\n",
       "  'ity Metrics than included in the `DataQualityPreset`. \\n\\n# How to read the tables\\n\\n* **Name**: the name of the Metric.  \\n* **Description**: plain text explanation. For Metrics, we also specify whether it applies to the whole dataset or individual columns.\\n* **Parameters**: required and optional parameters for the Metric or Preset. We also specify the defaults that apply if you do not pass a custom parameter.\\n\\n**Metric visualizations**. Each Metric includes a default render. To see the visualizati',\n",
       "  'igate the sections. \\n\\n# How to read the tables\\n\\n* **Name**: the name of the Test or Test preset.  \\n* **Description**: plain text explanation. For Tests, we specify whether it applies to the whole dataset or individual columns.\\n* **Parameters**: available configurations. \\n  * Required parameters are necessary for calculations, e.g. a column name for a column-level test.\\n  * Optional parameters modify how the underlying metric is calculated, e.g. which statistical test or correlation method is use'],\n",
       " ['l>| **Required:**<br>n/a<br><br>**Optional:**<ul><li>`display_name`</li></ul> |\\n| **HuggingFaceModel()** <br><br> Scores the text using the user-selected HuggingFace model.| See [docs](../customization/huggingface_descriptor.md) with some example models (classification by topic, emotion, etc.)|\\n| **HuggingFaceToxicityModel()** <ul><li> Detects hate speech using [HuggingFace Model](https://huggingface.co/facebook/roberta-hate-speech-dynabench-r4-target). </li><li> Returns predicted probability fo',\n",
       "  'xts (containing critical or pessimistic tone). Returns a label (NEGATIVE or POSITIVE) or score.| See [docs](../customization/llm_as_a_judge.md) for parameters.|\\n| **BiasLLMEval()** <br><br> Detects biased texts (containing prejudice for or against a person or group). Returns a label (BIAS or OK) or score.| See [docs](../customization/llm_as_a_judge.md) for parameters.|\\n| **ToxicityLLMEval()** <br><br> Detects toxic texts (containing harmful, offensive, or derogatory language). Returns a label (T',\n",
       "  'arget). </li><li> Returns predicted probability for the “hate” label. </li><li> Scale: 0 to 1. </li></ul> | **Optional**: <ul><li>`toxic_label=\"hate\"` (default)</li><li> `display_name`</li></ul> |\\n\\n# Data Drift\\n\\n**Defaults for Data Drift**. By default, all data drift metrics use the Evidently [drift detection logic](data-drift-algorithm.md) that selects a drift detection method based on feature type and volume. You always need a reference dataset.\\n\\nTo modify the logic or select a different test,'],\n",
       " ['*: the test fails if there is at least one empty column.|\\n| **TestNumberOfDuplicatedRows()** | Dataset-level. <br><br> Tests the number of duplicate rows against reference or a defined condition. |**Required**:<br> N/A <br><br> **Optional**:<br> N/A <br><br>**Test conditions**: <ul><li>*standard parameters*</li></ul>| Expects +/- 10% or none.<br><br>**With reference**: the test fails if the share of duplicate rows is over 10% higher or lower than in the reference.<br><br>**No reference**: the te',\n",
       "  '**With reference**: the test fails if the share of rows with missing values is over 10% higher than in reference. <br><br>**No reference**: the test fails if the dataset contains rows with missing values.|\\n| **TestNumberOfDifferentMissingValues()**| Dataset-level. <br><br> Tests the number of differently encoded missing values in the dataset against the reference or a defined condition. Detects 4 types of missing values by default and/or values from a user list. | **Required**:<br>N/A<br><br>**O',\n",
       "  ' in the reference.<br><br>**No reference**: the test fails if there is at least one duplicate row. |\\n| **TestNumberOfDuplicatedColumns()** | Dataset-level. <br><br> Tests the number of duplicate columns against reference or a defined condition. |**Required**:<br> N/A <br><br> **Optional**:<br> N/A <br><br>**Test conditions**: <ul><li>*standard parameters*</li></ul>| Expects =< or none.<br><br>**With reference**: the test fails if the number of duplicate columns is higher than in the reference.<b'],\n",
       " ['lumnsType()`\\n* `TestColumnShareOfMissingValues()` for all or specified `columns`\\n* `TestShareOfOutRangeValues()` for all numerical or specified `columns`\\n* `TestShareOfOutListValues()` for all categorical or specified  `columns`\\n* `TestMeanInNSigmas()` for all numerical or specified `columns`\\n\\n**Optional parameters**: \\n* `columns`\\n\\n</details>\\n\\n<details>\\n \\n<summary>Data Quality Test Preset</summary>\\n\\nPreset name: `DataQualityTestPreset()`\\n\\n**Composition**: \\n* `TestColumnShareOfMissingValues()` fo',\n",
       "  'sition**: \\n* `TestColumnShareOfMissingValues()` for all or specified `columns`\\n* `TestMostCommonValueShare()` for all or specified `columns`\\n* `TestNumberOfConstantColumns()`\\n* `TestNumberOfDuplicatedColumns()`\\n* `TestNumberOfDuplicatedRows()`\\n\\n**Optional parameters**: \\n* `columns`\\n\\n</details>\\n\\n<details>\\n \\n<summary>Data Drift Test Preset</summary>\\n\\nPreset name: `DataDriftTestPreset()`\\n\\n**Composition**: \\n* `TestShareOfDriftedColumns()`\\n* `TestColumnDrift()` for all or specified `columns`\\n\\n**Optio',\n",
       "  \"10%.<br><br>**With reference**: the test fails if the median value is different by more than 10%.<br><br>**No reference**: N/A |\\n| **TestColumnValueStd**(column_name='num-column')<br>| Column-level. <br><br> Tests the standard deviation of a given numerical column against reference or a defined condition. |   **Required**:<ul><li>`column_name`</li></ul> **Optional:**<br> N/A <br><br> **Test conditions**: <ul><li>*standard parameters*</li></ul> | Expects +/-10%.<br><br>**With reference**: the tes\"],\n",
       " ['in the training dataset.<br><br>Requires a training dataset. | **Required**:<ul><li>`k`</li><li>`column_name`</li></ul>**Optional**:<ul><li>-</li></ul> |\\n| **ScoreDistribution()** <br><br> Computes the predicted score entropy. Visualizes the distribution of the scores at `k` (and all scores, if available).<br><br>Applies only when the `recommendations_type` is a `score`. | **Required**:<ul><li>`k`</li></ul>**Optional**:<ul><li>-</li></ul> |\\n| **RecCasesTable()** <br><br> Shows the list of recomm',\n",
       "  'Evidently Metric**: `ScoreDistribution`\\n\\nThis metric computes the predicted score entropy. It applies only when the `recommendations_type` is a score.\\n\\n**Implementation**:\\n* Apply softmax transformation for top-K scores for all users.\\n* Compute the KL divergence (relative entropy in [scipy](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.entropy.html)). \\n\\nThe visualization shows the distribution of the predicted scores at K (and all scores, if available). \\n\\n# Item Bias \\n\\n![](../',\n",
       "  'icationProbDistribution()`- if probabilistic classification\\n* `ClassificationRocCurve()` - if probabilistic classification\\n* `ClassificationPRCurve()` - if probabilistic classification\\n* `ClassificationPRTable()` - if probabilistic classification\\n* `ClassificationQualityByFeatureTable()` for all or specified `columns`</li></ul>\\n\\n**Optional parameters**:\\n* `columns`\\n* `probas_threshold`\\n\\n</details>\\n\\n<details>\\n  \\n<summary>Text Overview Preset</summary>\\n\\n`TextOverviewPreset()` provides a summary fo'],\n",
       " ['ity Metrics than included in the `DataQualityPreset`. \\n\\n# How to read the tables\\n\\n* **Name**: the name of the Metric.  \\n* **Description**: plain text explanation. For Metrics, we also specify whether it applies to the whole dataset or individual columns.\\n* **Parameters**: required and optional parameters for the Metric or Preset. We also specify the defaults that apply if you do not pass a custom parameter.\\n\\n**Metric visualizations**. Each Metric includes a default render. To see the visualizati',\n",
       "  '%}\\n\\n# Metric Presets\\n\\n**Defaults**: Presets use the default parameters for each Metric. You can see them in the tables below. \\n\\n<details>\\n\\n<summary>Data Quality Preset</summary>\\n\\n`DataQualityPreset` captures column and dataset summaries. Input columns are required. Prediction and target are optional.\\n\\n**Composition**:\\n* `DatasetSummaryMetric()`\\n* `ColumnSummaryMetric()` for `all` or specified `сolumns`\\n* `DatasetMissingValuesMetric()`\\n\\n**Optional parameters**:\\n* `columns`\\n\\n</details>\\n\\n<details>\\n',\n",
       "  'lumnsType()`\\n* `TestColumnShareOfMissingValues()` for all or specified `columns`\\n* `TestShareOfOutRangeValues()` for all numerical or specified `columns`\\n* `TestShareOfOutListValues()` for all categorical or specified  `columns`\\n* `TestMeanInNSigmas()` for all numerical or specified `columns`\\n\\n**Optional parameters**: \\n* `columns`\\n\\n</details>\\n\\n<details>\\n \\n<summary>Data Quality Test Preset</summary>\\n\\nPreset name: `DataQualityTestPreset()`\\n\\n**Composition**: \\n* `TestColumnShareOfMissingValues()` fo'],\n",
       " ['In some tests and metrics, Evidently uses the default Data Drift Detection algorithm. It helps detect the distribution drift in the individual features, prediction, or target. This page describes how the **default** algorithm works.\\n\\n# How it works\\n\\nEvidently compares the distributions of the values in a given column (or columns) of the two datasets. You should pass these datasets as **reference** and **current**. Evidently applies several statistical tests and drift detection methods to detect ',\n",
       "  'ct a different test, you should set [data drift parameters](../customization/options-for-statistical-tests.md). \\n\\n| Test name | Description | Parameters | Default test conditions | \\n|---|---|---|---|\\n| **TestNumberOfDriftedColumns()** | Dataset-level. <br><br> Compares the distribution of each column in the current dataset to the reference and tests the number of drifting features against a defined condition.| **Required**:<br>N/A<br><br>**Optional:**<ul><li>`сolumns`</li><li>`stattest`(default=',\n",
       "  'tical tests and drift detection methods to detect if the distribution has changed significantly. It returns a \"drift detected\" or \"not detected\" result.\\n\\nThere is a default logic to choosing the appropriate drift test for each column. It is based on:\\n\\n* column type: categorical, numerical, text data or embeddings\\n* the number of observations in the reference dataset\\n* the number of unique values in the column (n\\\\_unique)\\n\\n## Tabular Data \\n\\n![](../.gitbook/assets/reports/metric_data_drift_table_2'],\n",
       " ['at each relevant item position within the top K. To do that, we sum up precision at all values of K when the item is relevant (e.g., Precision @1, Precision@2..), and divide it by the total number of relevant items in K.\\n\\n$$\\n\\\\text{AP@K} = \\\\frac{1}{N} \\\\sum_{k=1}^{K} Precision(k) \\\\times rel(k)\\n$$\\n\\nWhere *N* is the total number of relevant items at K, and *rel(k)* is equal to 1 if the item is relevant, and is 0 otherwise.\\n\\nExample: if K = 10, and items in positions 1, 2, and 10 are relevant, the fo',\n",
       "  ' 1 if any relevant item is included in K, or 0 otherwise.\\n* **Compute average hit rate**. The average of this metric is calculated across all users or queries.\\n\\n**Range**: 0 to 1, where 1 indicates that each user / query gets at least one relevant recommendation / retrieval.\\n\\n**Interpretation**: A higher Hit Rate indicates that a higher share of users / queries have relevant items in their lists. \\n\\n**Note**: the Hit Rate will typically increase for higher values of K (since there is a higher cha',\n",
       "  'ems in positions 1, 2, and 10 are relevant, the formula will look as:\\n\\n$$\\nAP@10 = \\\\frac{Precision@1+Precision@2+Precision@10}{3}\\n$$\\n\\n* **Compute Mean Average Precision (MAP) at K**. Average the results across all users (or queries) in the dataset.\\n\\n$$\\n\\\\text{MAP@K} = \\\\frac{1}{U} \\\\sum_{u=1}^{U} \\\\text{AP@K}_u\\n$$\\n\\nWhere *U* is the total number of users or queries in the dataset, and *AP* is the average precision for a given list.\\n\\n**Range**: 0 to 1.\\n\\n**Interpretation**: Higher MAP at K values indica']]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e24bdc4-fb5c-4df4-b00f-01903c4ed370",
   "metadata": {},
   "source": [
    "### Baseline answer generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ee992257-020d-461b-9b2f-928b93acb4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a request to the OpenAI to answer generated question with relevant context\n",
    "\n",
    "def generate_baseline_answer(query, relevant_chunks):\n",
    "    system_prompt = \"You are a helpful assistant thet answer a given question directly withou any preamble\"\n",
    "\n",
    "    user_prompt = \"\"\"\n",
    "    Your task is to answer the following query: \n",
    "    <query>\n",
    "    {query}\n",
    "    </query>\n",
    "    \n",
    "    You have access to the following documents which are meant to provide context as you answer the query:\n",
    "    <documents>\n",
    "    {context}\n",
    "    </documents>\n",
    "    \n",
    "    Please remain faithful to the underlying context, and deviate from it only if you haven't found the answer in the provided context. \n",
    "    Avoid providing any preamble!\n",
    "    Avoid providing any closing statement!\n",
    "    Please return the answer only\n",
    "    \"\"\"\n",
    "    \n",
    "    context = \"\\n\\n\".join(relevant_chunks)\n",
    "    formated_user_prompt = user_prompt.format(query=query, context=context)\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",  # Updated to a valid model\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": formated_user_prompt}\n",
    "        ],\n",
    "        max_tokens=400,  # Limits the response length\n",
    "        temperature=0.7,  # Controls randomness in the output\n",
    "        n=1\n",
    "    )\n",
    "    \n",
    "    completion_text = response.choices[0].message.content\n",
    "    return completion_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "8db672b0-f63a-400b-b00f-22e96d02dbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_answers = [generate_baseline_answer(generated_seed_queries[i], relevant_chunks[i]) for i in range(min(len(generated_seed_queries), len(relevant_chunks)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "ae366d95-3438-4d6c-8030-8e8c666e0e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_dataset = pd.DataFrame({\n",
    "    'Query': generated_seed_queries,\n",
    "    'Relevant chunks': relevant_chunks,\n",
    "    'Baseline_answers': baseline_answers\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "bdfc1029-34bb-4870-bcc2-0c32f56a0bc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Query</th>\n",
       "      <th>Relevant chunks</th>\n",
       "      <th>Baseline_answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"How does the TestShareOfColumnsWithMissingValues function determine if a dataset fails the test with reference?</td>\n",
       "      <td>[r&gt;&lt;br&gt;**With reference**: the test fails if the number of columns with missing values is higher than in reference.  &lt;br&gt;**No reference**: the test fails if the dataset contains columns with missing values.|\\n| **TestShareOfColumnsWithMissingValues()** | Dataset-level. &lt;br&gt;&lt;br&gt; Tests the share of columns that contain missing values in the dataset against the reference or a defined condition.| **Required**:&lt;br&gt; N/A &lt;br&gt;&lt;br&gt; **Optional**: &lt;ul&gt;&lt;li&gt;`missing_values = [], replace = True/False` (default , **With reference**: the test fails if the share of rows with missing values is over 10% higher than in reference. &lt;br&gt;&lt;br&gt;**No reference**: the test fails if the dataset contains rows with missing values.|\\n| **TestNumberOfDifferentMissingValues()**| Dataset-level. &lt;br&gt;&lt;br&gt; Tests the number of differently encoded missing values in the dataset against the reference or a defined condition. Detects 4 types of missing values by default and/or values from a user list. | **Required**:&lt;br&gt;N/A&lt;br&gt;&lt;br&gt;**O,  test fails if the dataset contains rows with missing values.|\\n| **TestShareOfRowsWithMissingValues()** | Dataset-level. &lt;br&gt;&lt;br&gt; Tests the share of rows that contain missing values against the reference or a defined condition. | **Required**:&lt;br&gt;N/A&lt;br&gt;&lt;br&gt;**Optional**:&lt;ul&gt;&lt;li&gt;`missing_values = [], replace = True/False` (default = default list)&lt;/li&gt;&lt;/ul&gt;**Test conditions** &lt;ul&gt;&lt;li&gt;*standard parameters*&lt;/li&gt;&lt;/ul&gt;| Expects up to +10% or 0.&lt;br&gt;&lt;br&gt;**With reference**: the test fails if the share of]</td>\n",
       "      <td>The TestShareOfColumnsWithMissingValues function determines that a dataset fails the test if the number of columns with missing values is higher than in the reference dataset.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What optional parameters can be included in the TestShareOfColumnsWithMissingValues function?</td>\n",
       "      <td>[the Test's defaults. You can see them in the tables below. The listed Preset parameters apply to the relevant individual Tests inside the Preset.\\n\\n&lt;details&gt;\\n \\n&lt;summary&gt;NoTargetPerformance Test Preset&lt;/summary&gt;\\n\\nPreset name: `NoTargetPerformanceTestPreset()`\\n\\n**Composition**: \\n* `TestShareOfDriftedColumns()`\\n* `TestColumnDrift(column_name=prediction)`\\n* `TestColumnShareOfMissingValues()` for `all` or `сolumns` if provided\\n* `TestShareOfOutRangeValues()` for all numerical or specified `columns`\\n* , lumnsType()`\\n* `TestColumnShareOfMissingValues()` for all or specified `columns`\\n* `TestShareOfOutRangeValues()` for all numerical or specified `columns`\\n* `TestShareOfOutListValues()` for all categorical or specified  `columns`\\n* `TestMeanInNSigmas()` for all numerical or specified `columns`\\n\\n**Optional parameters**: \\n* `columns`\\n\\n&lt;/details&gt;\\n\\n&lt;details&gt;\\n \\n&lt;summary&gt;Data Quality Test Preset&lt;/summary&gt;\\n\\nPreset name: `DataQualityTestPreset()`\\n\\n**Composition**: \\n* `TestColumnShareOfMissingValues()` fo, **: N/A |\\n\\n## Column Values\\n\\n| Test name  | Description | Parameters | Default test conditions | \\n|---|---|---|---|\\n| **TestColumnValueMin**(column_name='num-column') | Column-level. &lt;br&gt;&lt;br&gt; Tests the minimum value of a given numerical column against reference or a defined condition. |  **Required**:&lt;ul&gt;&lt;li&gt;`column_name`&lt;/li&gt;&lt;/ul&gt; **Optional:** N/A &lt;br&gt;&lt;br&gt; **Test conditions**: &lt;ul&gt;&lt;li&gt;*standard parameters*&lt;/li&gt;&lt;/ul&gt; | Expects not lower.&lt;br&gt;&lt;br&gt;**With reference**: the test fails if the minimum ]</td>\n",
       "      <td>The optional parameters for the `TestShareOfColumnsWithMissingValues` function are `columns`.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is the purpose of the HuggingFaceModel function?</td>\n",
       "      <td>[tems by a chosen characteristic.\\n\\nThe visualization shows:\\n* The distribution of items in the training set for the defined `column_name` (with duplicates dropped). This represents the item catalog by this dimension. \\n* The distribution of the recommended items for the defined `column_name` in the current and reference (if available) datasets. \\n\\nThis visualization helps see the patterns in the model recommendations. In a simplified example, you might observe that the training data contains 3x com, ity Metrics than included in the `DataQualityPreset`. \\n\\n# How to read the tables\\n\\n* **Name**: the name of the Metric.  \\n* **Description**: plain text explanation. For Metrics, we also specify whether it applies to the whole dataset or individual columns.\\n* **Parameters**: required and optional parameters for the Metric or Preset. We also specify the defaults that apply if you do not pass a custom parameter.\\n\\n**Metric visualizations**. Each Metric includes a default render. To see the visualizati, igate the sections. \\n\\n# How to read the tables\\n\\n* **Name**: the name of the Test or Test preset.  \\n* **Description**: plain text explanation. For Tests, we specify whether it applies to the whole dataset or individual columns.\\n* **Parameters**: available configurations. \\n  * Required parameters are necessary for calculations, e.g. a column name for a column-level test.\\n  * Optional parameters modify how the underlying metric is calculated, e.g. which statistical test or correlation method is use]</td>\n",
       "      <td>The purpose of the HuggingFaceModel function is not specified in the provided documents.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How does the HuggingFaceToxicityModel function detect hate speech?</td>\n",
       "      <td>[l&gt;| **Required:**&lt;br&gt;n/a&lt;br&gt;&lt;br&gt;**Optional:**&lt;ul&gt;&lt;li&gt;`display_name`&lt;/li&gt;&lt;/ul&gt; |\\n| **HuggingFaceModel()** &lt;br&gt;&lt;br&gt; Scores the text using the user-selected HuggingFace model.| See [docs](../customization/huggingface_descriptor.md) with some example models (classification by topic, emotion, etc.)|\\n| **HuggingFaceToxicityModel()** &lt;ul&gt;&lt;li&gt; Detects hate speech using [HuggingFace Model](https://huggingface.co/facebook/roberta-hate-speech-dynabench-r4-target). &lt;/li&gt;&lt;li&gt; Returns predicted probability fo, xts (containing critical or pessimistic tone). Returns a label (NEGATIVE or POSITIVE) or score.| See [docs](../customization/llm_as_a_judge.md) for parameters.|\\n| **BiasLLMEval()** &lt;br&gt;&lt;br&gt; Detects biased texts (containing prejudice for or against a person or group). Returns a label (BIAS or OK) or score.| See [docs](../customization/llm_as_a_judge.md) for parameters.|\\n| **ToxicityLLMEval()** &lt;br&gt;&lt;br&gt; Detects toxic texts (containing harmful, offensive, or derogatory language). Returns a label (T, arget). &lt;/li&gt;&lt;li&gt; Returns predicted probability for the “hate” label. &lt;/li&gt;&lt;li&gt; Scale: 0 to 1. &lt;/li&gt;&lt;/ul&gt; | **Optional**: &lt;ul&gt;&lt;li&gt;`toxic_label=\"hate\"` (default)&lt;/li&gt;&lt;li&gt; `display_name`&lt;/li&gt;&lt;/ul&gt; |\\n\\n# Data Drift\\n\\n**Defaults for Data Drift**. By default, all data drift metrics use the Evidently [drift detection logic](data-drift-algorithm.md) that selects a drift detection method based on feature type and volume. You always need a reference dataset.\\n\\nTo modify the logic or select a different test,]</td>\n",
       "      <td>The HuggingFaceToxicityModel function detects hate speech using the HuggingFace model found at https://huggingface.co/facebook/roberta-hate-speech-dynabench-r4-target. It returns a predicted probability for the \"hate\" label, with a scale from 0 to 1.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What condition causes the TestNumberOfDuplicatedRows to fail without a reference?</td>\n",
       "      <td>[*: the test fails if there is at least one empty column.|\\n| **TestNumberOfDuplicatedRows()** | Dataset-level. &lt;br&gt;&lt;br&gt; Tests the number of duplicate rows against reference or a defined condition. |**Required**:&lt;br&gt; N/A &lt;br&gt;&lt;br&gt; **Optional**:&lt;br&gt; N/A &lt;br&gt;&lt;br&gt;**Test conditions**: &lt;ul&gt;&lt;li&gt;*standard parameters*&lt;/li&gt;&lt;/ul&gt;| Expects +/- 10% or none.&lt;br&gt;&lt;br&gt;**With reference**: the test fails if the share of duplicate rows is over 10% higher or lower than in the reference.&lt;br&gt;&lt;br&gt;**No reference**: the te, **With reference**: the test fails if the share of rows with missing values is over 10% higher than in reference. &lt;br&gt;&lt;br&gt;**No reference**: the test fails if the dataset contains rows with missing values.|\\n| **TestNumberOfDifferentMissingValues()**| Dataset-level. &lt;br&gt;&lt;br&gt; Tests the number of differently encoded missing values in the dataset against the reference or a defined condition. Detects 4 types of missing values by default and/or values from a user list. | **Required**:&lt;br&gt;N/A&lt;br&gt;&lt;br&gt;**O,  in the reference.&lt;br&gt;&lt;br&gt;**No reference**: the test fails if there is at least one duplicate row. |\\n| **TestNumberOfDuplicatedColumns()** | Dataset-level. &lt;br&gt;&lt;br&gt; Tests the number of duplicate columns against reference or a defined condition. |**Required**:&lt;br&gt; N/A &lt;br&gt;&lt;br&gt; **Optional**:&lt;br&gt; N/A &lt;br&gt;&lt;br&gt;**Test conditions**: &lt;ul&gt;&lt;li&gt;*standard parameters*&lt;/li&gt;&lt;/ul&gt;| Expects =&lt; or none.&lt;br&gt;&lt;br&gt;**With reference**: the test fails if the number of duplicate columns is higher than in the reference.&lt;b]</td>\n",
       "      <td>The test fails if there is at least one duplicate row.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>What is measured by the TestShareOfDriftedColumns function?</td>\n",
       "      <td>[lumnsType()`\\n* `TestColumnShareOfMissingValues()` for all or specified `columns`\\n* `TestShareOfOutRangeValues()` for all numerical or specified `columns`\\n* `TestShareOfOutListValues()` for all categorical or specified  `columns`\\n* `TestMeanInNSigmas()` for all numerical or specified `columns`\\n\\n**Optional parameters**: \\n* `columns`\\n\\n&lt;/details&gt;\\n\\n&lt;details&gt;\\n \\n&lt;summary&gt;Data Quality Test Preset&lt;/summary&gt;\\n\\nPreset name: `DataQualityTestPreset()`\\n\\n**Composition**: \\n* `TestColumnShareOfMissingValues()` fo, sition**: \\n* `TestColumnShareOfMissingValues()` for all or specified `columns`\\n* `TestMostCommonValueShare()` for all or specified `columns`\\n* `TestNumberOfConstantColumns()`\\n* `TestNumberOfDuplicatedColumns()`\\n* `TestNumberOfDuplicatedRows()`\\n\\n**Optional parameters**: \\n* `columns`\\n\\n&lt;/details&gt;\\n\\n&lt;details&gt;\\n \\n&lt;summary&gt;Data Drift Test Preset&lt;/summary&gt;\\n\\nPreset name: `DataDriftTestPreset()`\\n\\n**Composition**: \\n* `TestShareOfDriftedColumns()`\\n* `TestColumnDrift()` for all or specified `columns`\\n\\n**Optio, 10%.&lt;br&gt;&lt;br&gt;**With reference**: the test fails if the median value is different by more than 10%.&lt;br&gt;&lt;br&gt;**No reference**: N/A |\\n| **TestColumnValueStd**(column_name='num-column')&lt;br&gt;| Column-level. &lt;br&gt;&lt;br&gt; Tests the standard deviation of a given numerical column against reference or a defined condition. |   **Required**:&lt;ul&gt;&lt;li&gt;`column_name`&lt;/li&gt;&lt;/ul&gt; **Optional:**&lt;br&gt; N/A &lt;br&gt;&lt;br&gt; **Test conditions**: &lt;ul&gt;&lt;li&gt;*standard parameters*&lt;/li&gt;&lt;/ul&gt; | Expects +/-10%.&lt;br&gt;&lt;br&gt;**With reference**: the tes]</td>\n",
       "      <td>The `TestShareOfDriftedColumns` function measures the proportion of columns that have drifted between datasets.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>What are the required and optional parameters for the ScoreDistribution function?</td>\n",
       "      <td>[in the training dataset.&lt;br&gt;&lt;br&gt;Requires a training dataset. | **Required**:&lt;ul&gt;&lt;li&gt;`k`&lt;/li&gt;&lt;li&gt;`column_name`&lt;/li&gt;&lt;/ul&gt;**Optional**:&lt;ul&gt;&lt;li&gt;-&lt;/li&gt;&lt;/ul&gt; |\\n| **ScoreDistribution()** &lt;br&gt;&lt;br&gt; Computes the predicted score entropy. Visualizes the distribution of the scores at `k` (and all scores, if available).&lt;br&gt;&lt;br&gt;Applies only when the `recommendations_type` is a `score`. | **Required**:&lt;ul&gt;&lt;li&gt;`k`&lt;/li&gt;&lt;/ul&gt;**Optional**:&lt;ul&gt;&lt;li&gt;-&lt;/li&gt;&lt;/ul&gt; |\\n| **RecCasesTable()** &lt;br&gt;&lt;br&gt; Shows the list of recomm, Evidently Metric**: `ScoreDistribution`\\n\\nThis metric computes the predicted score entropy. It applies only when the `recommendations_type` is a score.\\n\\n**Implementation**:\\n* Apply softmax transformation for top-K scores for all users.\\n* Compute the KL divergence (relative entropy in [scipy](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.entropy.html)). \\n\\nThe visualization shows the distribution of the predicted scores at K (and all scores, if available). \\n\\n# Item Bias \\n\\n![](../, icationProbDistribution()`- if probabilistic classification\\n* `ClassificationRocCurve()` - if probabilistic classification\\n* `ClassificationPRCurve()` - if probabilistic classification\\n* `ClassificationPRTable()` - if probabilistic classification\\n* `ClassificationQualityByFeatureTable()` for all or specified `columns`&lt;/li&gt;&lt;/ul&gt;\\n\\n**Optional parameters**:\\n* `columns`\\n* `probas_threshold`\\n\\n&lt;/details&gt;\\n\\n&lt;details&gt;\\n  \\n&lt;summary&gt;Text Overview Preset&lt;/summary&gt;\\n\\n`TextOverviewPreset()` provides a summary fo]</td>\n",
       "      <td>**Required**: `k`  \\n**Optional**: None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>What is the role of the ColumnSummaryMetric in the DataQualityPreset?</td>\n",
       "      <td>[ity Metrics than included in the `DataQualityPreset`. \\n\\n# How to read the tables\\n\\n* **Name**: the name of the Metric.  \\n* **Description**: plain text explanation. For Metrics, we also specify whether it applies to the whole dataset or individual columns.\\n* **Parameters**: required and optional parameters for the Metric or Preset. We also specify the defaults that apply if you do not pass a custom parameter.\\n\\n**Metric visualizations**. Each Metric includes a default render. To see the visualizati, %}\\n\\n# Metric Presets\\n\\n**Defaults**: Presets use the default parameters for each Metric. You can see them in the tables below. \\n\\n&lt;details&gt;\\n\\n&lt;summary&gt;Data Quality Preset&lt;/summary&gt;\\n\\n`DataQualityPreset` captures column and dataset summaries. Input columns are required. Prediction and target are optional.\\n\\n**Composition**:\\n* `DatasetSummaryMetric()`\\n* `ColumnSummaryMetric()` for `all` or specified `сolumns`\\n* `DatasetMissingValuesMetric()`\\n\\n**Optional parameters**:\\n* `columns`\\n\\n&lt;/details&gt;\\n\\n&lt;details&gt;\\n, lumnsType()`\\n* `TestColumnShareOfMissingValues()` for all or specified `columns`\\n* `TestShareOfOutRangeValues()` for all numerical or specified `columns`\\n* `TestShareOfOutListValues()` for all categorical or specified  `columns`\\n* `TestMeanInNSigmas()` for all numerical or specified `columns`\\n\\n**Optional parameters**: \\n* `columns`\\n\\n&lt;/details&gt;\\n\\n&lt;details&gt;\\n \\n&lt;summary&gt;Data Quality Test Preset&lt;/summary&gt;\\n\\nPreset name: `DataQualityTestPreset()`\\n\\n**Composition**: \\n* `TestColumnShareOfMissingValues()` fo]</td>\n",
       "      <td>The `ColumnSummaryMetric` in the `DataQualityPreset` is used to capture summaries for each column, either for all columns or specified columns.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>How does the drift detection method choose the appropriate test for each column?</td>\n",
       "      <td>[In some tests and metrics, Evidently uses the default Data Drift Detection algorithm. It helps detect the distribution drift in the individual features, prediction, or target. This page describes how the **default** algorithm works.\\n\\n# How it works\\n\\nEvidently compares the distributions of the values in a given column (or columns) of the two datasets. You should pass these datasets as **reference** and **current**. Evidently applies several statistical tests and drift detection methods to detect , ct a different test, you should set [data drift parameters](../customization/options-for-statistical-tests.md). \\n\\n| Test name | Description | Parameters | Default test conditions | \\n|---|---|---|---|\\n| **TestNumberOfDriftedColumns()** | Dataset-level. &lt;br&gt;&lt;br&gt; Compares the distribution of each column in the current dataset to the reference and tests the number of drifting features against a defined condition.| **Required**:&lt;br&gt;N/A&lt;br&gt;&lt;br&gt;**Optional:**&lt;ul&gt;&lt;li&gt;`сolumns`&lt;/li&gt;&lt;li&gt;`stattest`(default=, tical tests and drift detection methods to detect if the distribution has changed significantly. It returns a \"drift detected\" or \"not detected\" result.\\n\\nThere is a default logic to choosing the appropriate drift test for each column. It is based on:\\n\\n* column type: categorical, numerical, text data or embeddings\\n* the number of observations in the reference dataset\\n* the number of unique values in the column (n\\_unique)\\n\\n## Tabular Data \\n\\n![](../.gitbook/assets/reports/metric_data_drift_table_2]</td>\n",
       "      <td>The drift detection method chooses the appropriate test for each column based on the column type (categorical, numerical, text data, or embeddings), the number of observations in the reference dataset, and the number of unique values in the column.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>How is AP@K calculated in the context of relevant item positions?\"</td>\n",
       "      <td>[at each relevant item position within the top K. To do that, we sum up precision at all values of K when the item is relevant (e.g., Precision @1, Precision@2..), and divide it by the total number of relevant items in K.\\n\\n$$\\n\\text{AP@K} = \\frac{1}{N} \\sum_{k=1}^{K} Precision(k) \\times rel(k)\\n$$\\n\\nWhere *N* is the total number of relevant items at K, and *rel(k)* is equal to 1 if the item is relevant, and is 0 otherwise.\\n\\nExample: if K = 10, and items in positions 1, 2, and 10 are relevant, the fo,  1 if any relevant item is included in K, or 0 otherwise.\\n* **Compute average hit rate**. The average of this metric is calculated across all users or queries.\\n\\n**Range**: 0 to 1, where 1 indicates that each user / query gets at least one relevant recommendation / retrieval.\\n\\n**Interpretation**: A higher Hit Rate indicates that a higher share of users / queries have relevant items in their lists. \\n\\n**Note**: the Hit Rate will typically increase for higher values of K (since there is a higher cha, ems in positions 1, 2, and 10 are relevant, the formula will look as:\\n\\n$$\\nAP@10 = \\frac{Precision@1+Precision@2+Precision@10}{3}\\n$$\\n\\n* **Compute Mean Average Precision (MAP) at K**. Average the results across all users (or queries) in the dataset.\\n\\n$$\\n\\text{MAP@K} = \\frac{1}{U} \\sum_{u=1}^{U} \\text{AP@K}_u\\n$$\\n\\nWhere *U* is the total number of users or queries in the dataset, and *AP* is the average precision for a given list.\\n\\n**Range**: 0 to 1.\\n\\n**Interpretation**: Higher MAP at K values indica]</td>\n",
       "      <td>AP@K is calculated by summing the precision at each position up to K where the item is relevant and dividing by the total number of relevant items within K. The formula is:\\n\\n$$\\n\\text{AP@K} = \\frac{1}{N} \\sum_{k=1}^{K} Precision(k) \\times rel(k)\\n$$\\n\\nwhere *N* is the total number of relevant items in K, and *rel(k)* is 1 if the item at position k is relevant, otherwise 0.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                              Query  \\\n",
       "0  \"How does the TestShareOfColumnsWithMissingValues function determine if a dataset fails the test with reference?   \n",
       "1                     What optional parameters can be included in the TestShareOfColumnsWithMissingValues function?   \n",
       "2                                                             What is the purpose of the HuggingFaceModel function?   \n",
       "3                                                How does the HuggingFaceToxicityModel function detect hate speech?   \n",
       "4                                 What condition causes the TestNumberOfDuplicatedRows to fail without a reference?   \n",
       "5                                                       What is measured by the TestShareOfDriftedColumns function?   \n",
       "6                                 What are the required and optional parameters for the ScoreDistribution function?   \n",
       "7                                             What is the role of the ColumnSummaryMetric in the DataQualityPreset?   \n",
       "8                                  How does the drift detection method choose the appropriate test for each column?   \n",
       "9                                                How is AP@K calculated in the context of relevant item positions?\"   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Relevant chunks  \\\n",
       "0                                                [r><br>**With reference**: the test fails if the number of columns with missing values is higher than in reference.  <br>**No reference**: the test fails if the dataset contains columns with missing values.|\\n| **TestShareOfColumnsWithMissingValues()** | Dataset-level. <br><br> Tests the share of columns that contain missing values in the dataset against the reference or a defined condition.| **Required**:<br> N/A <br><br> **Optional**: <ul><li>`missing_values = [], replace = True/False` (default , **With reference**: the test fails if the share of rows with missing values is over 10% higher than in reference. <br><br>**No reference**: the test fails if the dataset contains rows with missing values.|\\n| **TestNumberOfDifferentMissingValues()**| Dataset-level. <br><br> Tests the number of differently encoded missing values in the dataset against the reference or a defined condition. Detects 4 types of missing values by default and/or values from a user list. | **Required**:<br>N/A<br><br>**O,  test fails if the dataset contains rows with missing values.|\\n| **TestShareOfRowsWithMissingValues()** | Dataset-level. <br><br> Tests the share of rows that contain missing values against the reference or a defined condition. | **Required**:<br>N/A<br><br>**Optional**:<ul><li>`missing_values = [], replace = True/False` (default = default list)</li></ul>**Test conditions** <ul><li>*standard parameters*</li></ul>| Expects up to +10% or 0.<br><br>**With reference**: the test fails if the share of]   \n",
       "1              [the Test's defaults. You can see them in the tables below. The listed Preset parameters apply to the relevant individual Tests inside the Preset.\\n\\n<details>\\n \\n<summary>NoTargetPerformance Test Preset</summary>\\n\\nPreset name: `NoTargetPerformanceTestPreset()`\\n\\n**Composition**: \\n* `TestShareOfDriftedColumns()`\\n* `TestColumnDrift(column_name=prediction)`\\n* `TestColumnShareOfMissingValues()` for `all` or `сolumns` if provided\\n* `TestShareOfOutRangeValues()` for all numerical or specified `columns`\\n* , lumnsType()`\\n* `TestColumnShareOfMissingValues()` for all or specified `columns`\\n* `TestShareOfOutRangeValues()` for all numerical or specified `columns`\\n* `TestShareOfOutListValues()` for all categorical or specified  `columns`\\n* `TestMeanInNSigmas()` for all numerical or specified `columns`\\n\\n**Optional parameters**: \\n* `columns`\\n\\n</details>\\n\\n<details>\\n \\n<summary>Data Quality Test Preset</summary>\\n\\nPreset name: `DataQualityTestPreset()`\\n\\n**Composition**: \\n* `TestColumnShareOfMissingValues()` fo, **: N/A |\\n\\n## Column Values\\n\\n| Test name  | Description | Parameters | Default test conditions | \\n|---|---|---|---|\\n| **TestColumnValueMin**(column_name='num-column') | Column-level. <br><br> Tests the minimum value of a given numerical column against reference or a defined condition. |  **Required**:<ul><li>`column_name`</li></ul> **Optional:** N/A <br><br> **Test conditions**: <ul><li>*standard parameters*</li></ul> | Expects not lower.<br><br>**With reference**: the test fails if the minimum ]   \n",
       "2                             [tems by a chosen characteristic.\\n\\nThe visualization shows:\\n* The distribution of items in the training set for the defined `column_name` (with duplicates dropped). This represents the item catalog by this dimension. \\n* The distribution of the recommended items for the defined `column_name` in the current and reference (if available) datasets. \\n\\nThis visualization helps see the patterns in the model recommendations. In a simplified example, you might observe that the training data contains 3x com, ity Metrics than included in the `DataQualityPreset`. \\n\\n# How to read the tables\\n\\n* **Name**: the name of the Metric.  \\n* **Description**: plain text explanation. For Metrics, we also specify whether it applies to the whole dataset or individual columns.\\n* **Parameters**: required and optional parameters for the Metric or Preset. We also specify the defaults that apply if you do not pass a custom parameter.\\n\\n**Metric visualizations**. Each Metric includes a default render. To see the visualizati, igate the sections. \\n\\n# How to read the tables\\n\\n* **Name**: the name of the Test or Test preset.  \\n* **Description**: plain text explanation. For Tests, we specify whether it applies to the whole dataset or individual columns.\\n* **Parameters**: available configurations. \\n  * Required parameters are necessary for calculations, e.g. a column name for a column-level test.\\n  * Optional parameters modify how the underlying metric is calculated, e.g. which statistical test or correlation method is use]   \n",
       "3                                         [l>| **Required:**<br>n/a<br><br>**Optional:**<ul><li>`display_name`</li></ul> |\\n| **HuggingFaceModel()** <br><br> Scores the text using the user-selected HuggingFace model.| See [docs](../customization/huggingface_descriptor.md) with some example models (classification by topic, emotion, etc.)|\\n| **HuggingFaceToxicityModel()** <ul><li> Detects hate speech using [HuggingFace Model](https://huggingface.co/facebook/roberta-hate-speech-dynabench-r4-target). </li><li> Returns predicted probability fo, xts (containing critical or pessimistic tone). Returns a label (NEGATIVE or POSITIVE) or score.| See [docs](../customization/llm_as_a_judge.md) for parameters.|\\n| **BiasLLMEval()** <br><br> Detects biased texts (containing prejudice for or against a person or group). Returns a label (BIAS or OK) or score.| See [docs](../customization/llm_as_a_judge.md) for parameters.|\\n| **ToxicityLLMEval()** <br><br> Detects toxic texts (containing harmful, offensive, or derogatory language). Returns a label (T, arget). </li><li> Returns predicted probability for the “hate” label. </li><li> Scale: 0 to 1. </li></ul> | **Optional**: <ul><li>`toxic_label=\"hate\"` (default)</li><li> `display_name`</li></ul> |\\n\\n# Data Drift\\n\\n**Defaults for Data Drift**. By default, all data drift metrics use the Evidently [drift detection logic](data-drift-algorithm.md) that selects a drift detection method based on feature type and volume. You always need a reference dataset.\\n\\nTo modify the logic or select a different test,]   \n",
       "4                                                [*: the test fails if there is at least one empty column.|\\n| **TestNumberOfDuplicatedRows()** | Dataset-level. <br><br> Tests the number of duplicate rows against reference or a defined condition. |**Required**:<br> N/A <br><br> **Optional**:<br> N/A <br><br>**Test conditions**: <ul><li>*standard parameters*</li></ul>| Expects +/- 10% or none.<br><br>**With reference**: the test fails if the share of duplicate rows is over 10% higher or lower than in the reference.<br><br>**No reference**: the te, **With reference**: the test fails if the share of rows with missing values is over 10% higher than in reference. <br><br>**No reference**: the test fails if the dataset contains rows with missing values.|\\n| **TestNumberOfDifferentMissingValues()**| Dataset-level. <br><br> Tests the number of differently encoded missing values in the dataset against the reference or a defined condition. Detects 4 types of missing values by default and/or values from a user list. | **Required**:<br>N/A<br><br>**O,  in the reference.<br><br>**No reference**: the test fails if there is at least one duplicate row. |\\n| **TestNumberOfDuplicatedColumns()** | Dataset-level. <br><br> Tests the number of duplicate columns against reference or a defined condition. |**Required**:<br> N/A <br><br> **Optional**:<br> N/A <br><br>**Test conditions**: <ul><li>*standard parameters*</li></ul>| Expects =< or none.<br><br>**With reference**: the test fails if the number of duplicate columns is higher than in the reference.<b]   \n",
       "5          [lumnsType()`\\n* `TestColumnShareOfMissingValues()` for all or specified `columns`\\n* `TestShareOfOutRangeValues()` for all numerical or specified `columns`\\n* `TestShareOfOutListValues()` for all categorical or specified  `columns`\\n* `TestMeanInNSigmas()` for all numerical or specified `columns`\\n\\n**Optional parameters**: \\n* `columns`\\n\\n</details>\\n\\n<details>\\n \\n<summary>Data Quality Test Preset</summary>\\n\\nPreset name: `DataQualityTestPreset()`\\n\\n**Composition**: \\n* `TestColumnShareOfMissingValues()` fo, sition**: \\n* `TestColumnShareOfMissingValues()` for all or specified `columns`\\n* `TestMostCommonValueShare()` for all or specified `columns`\\n* `TestNumberOfConstantColumns()`\\n* `TestNumberOfDuplicatedColumns()`\\n* `TestNumberOfDuplicatedRows()`\\n\\n**Optional parameters**: \\n* `columns`\\n\\n</details>\\n\\n<details>\\n \\n<summary>Data Drift Test Preset</summary>\\n\\nPreset name: `DataDriftTestPreset()`\\n\\n**Composition**: \\n* `TestShareOfDriftedColumns()`\\n* `TestColumnDrift()` for all or specified `columns`\\n\\n**Optio, 10%.<br><br>**With reference**: the test fails if the median value is different by more than 10%.<br><br>**No reference**: N/A |\\n| **TestColumnValueStd**(column_name='num-column')<br>| Column-level. <br><br> Tests the standard deviation of a given numerical column against reference or a defined condition. |   **Required**:<ul><li>`column_name`</li></ul> **Optional:**<br> N/A <br><br> **Test conditions**: <ul><li>*standard parameters*</li></ul> | Expects +/-10%.<br><br>**With reference**: the tes]   \n",
       "6                     [in the training dataset.<br><br>Requires a training dataset. | **Required**:<ul><li>`k`</li><li>`column_name`</li></ul>**Optional**:<ul><li>-</li></ul> |\\n| **ScoreDistribution()** <br><br> Computes the predicted score entropy. Visualizes the distribution of the scores at `k` (and all scores, if available).<br><br>Applies only when the `recommendations_type` is a `score`. | **Required**:<ul><li>`k`</li></ul>**Optional**:<ul><li>-</li></ul> |\\n| **RecCasesTable()** <br><br> Shows the list of recomm, Evidently Metric**: `ScoreDistribution`\\n\\nThis metric computes the predicted score entropy. It applies only when the `recommendations_type` is a score.\\n\\n**Implementation**:\\n* Apply softmax transformation for top-K scores for all users.\\n* Compute the KL divergence (relative entropy in [scipy](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.entropy.html)). \\n\\nThe visualization shows the distribution of the predicted scores at K (and all scores, if available). \\n\\n# Item Bias \\n\\n![](../, icationProbDistribution()`- if probabilistic classification\\n* `ClassificationRocCurve()` - if probabilistic classification\\n* `ClassificationPRCurve()` - if probabilistic classification\\n* `ClassificationPRTable()` - if probabilistic classification\\n* `ClassificationQualityByFeatureTable()` for all or specified `columns`</li></ul>\\n\\n**Optional parameters**:\\n* `columns`\\n* `probas_threshold`\\n\\n</details>\\n\\n<details>\\n  \\n<summary>Text Overview Preset</summary>\\n\\n`TextOverviewPreset()` provides a summary fo]   \n",
       "7  [ity Metrics than included in the `DataQualityPreset`. \\n\\n# How to read the tables\\n\\n* **Name**: the name of the Metric.  \\n* **Description**: plain text explanation. For Metrics, we also specify whether it applies to the whole dataset or individual columns.\\n* **Parameters**: required and optional parameters for the Metric or Preset. We also specify the defaults that apply if you do not pass a custom parameter.\\n\\n**Metric visualizations**. Each Metric includes a default render. To see the visualizati, %}\\n\\n# Metric Presets\\n\\n**Defaults**: Presets use the default parameters for each Metric. You can see them in the tables below. \\n\\n<details>\\n\\n<summary>Data Quality Preset</summary>\\n\\n`DataQualityPreset` captures column and dataset summaries. Input columns are required. Prediction and target are optional.\\n\\n**Composition**:\\n* `DatasetSummaryMetric()`\\n* `ColumnSummaryMetric()` for `all` or specified `сolumns`\\n* `DatasetMissingValuesMetric()`\\n\\n**Optional parameters**:\\n* `columns`\\n\\n</details>\\n\\n<details>\\n, lumnsType()`\\n* `TestColumnShareOfMissingValues()` for all or specified `columns`\\n* `TestShareOfOutRangeValues()` for all numerical or specified `columns`\\n* `TestShareOfOutListValues()` for all categorical or specified  `columns`\\n* `TestMeanInNSigmas()` for all numerical or specified `columns`\\n\\n**Optional parameters**: \\n* `columns`\\n\\n</details>\\n\\n<details>\\n \\n<summary>Data Quality Test Preset</summary>\\n\\nPreset name: `DataQualityTestPreset()`\\n\\n**Composition**: \\n* `TestColumnShareOfMissingValues()` fo]   \n",
       "8                                 [In some tests and metrics, Evidently uses the default Data Drift Detection algorithm. It helps detect the distribution drift in the individual features, prediction, or target. This page describes how the **default** algorithm works.\\n\\n# How it works\\n\\nEvidently compares the distributions of the values in a given column (or columns) of the two datasets. You should pass these datasets as **reference** and **current**. Evidently applies several statistical tests and drift detection methods to detect , ct a different test, you should set [data drift parameters](../customization/options-for-statistical-tests.md). \\n\\n| Test name | Description | Parameters | Default test conditions | \\n|---|---|---|---|\\n| **TestNumberOfDriftedColumns()** | Dataset-level. <br><br> Compares the distribution of each column in the current dataset to the reference and tests the number of drifting features against a defined condition.| **Required**:<br>N/A<br><br>**Optional:**<ul><li>`сolumns`</li><li>`stattest`(default=, tical tests and drift detection methods to detect if the distribution has changed significantly. It returns a \"drift detected\" or \"not detected\" result.\\n\\nThere is a default logic to choosing the appropriate drift test for each column. It is based on:\\n\\n* column type: categorical, numerical, text data or embeddings\\n* the number of observations in the reference dataset\\n* the number of unique values in the column (n\\_unique)\\n\\n## Tabular Data \\n\\n![](../.gitbook/assets/reports/metric_data_drift_table_2]   \n",
       "9                    [at each relevant item position within the top K. To do that, we sum up precision at all values of K when the item is relevant (e.g., Precision @1, Precision@2..), and divide it by the total number of relevant items in K.\\n\\n$$\\n\\text{AP@K} = \\frac{1}{N} \\sum_{k=1}^{K} Precision(k) \\times rel(k)\\n$$\\n\\nWhere *N* is the total number of relevant items at K, and *rel(k)* is equal to 1 if the item is relevant, and is 0 otherwise.\\n\\nExample: if K = 10, and items in positions 1, 2, and 10 are relevant, the fo,  1 if any relevant item is included in K, or 0 otherwise.\\n* **Compute average hit rate**. The average of this metric is calculated across all users or queries.\\n\\n**Range**: 0 to 1, where 1 indicates that each user / query gets at least one relevant recommendation / retrieval.\\n\\n**Interpretation**: A higher Hit Rate indicates that a higher share of users / queries have relevant items in their lists. \\n\\n**Note**: the Hit Rate will typically increase for higher values of K (since there is a higher cha, ems in positions 1, 2, and 10 are relevant, the formula will look as:\\n\\n$$\\nAP@10 = \\frac{Precision@1+Precision@2+Precision@10}{3}\\n$$\\n\\n* **Compute Mean Average Precision (MAP) at K**. Average the results across all users (or queries) in the dataset.\\n\\n$$\\n\\text{MAP@K} = \\frac{1}{U} \\sum_{u=1}^{U} \\text{AP@K}_u\\n$$\\n\\nWhere *U* is the total number of users or queries in the dataset, and *AP* is the average precision for a given list.\\n\\n**Range**: 0 to 1.\\n\\n**Interpretation**: Higher MAP at K values indica]   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                             Baseline_answers  \n",
       "0                                                                                                                                                                                                             The TestShareOfColumnsWithMissingValues function determines that a dataset fails the test if the number of columns with missing values is higher than in the reference dataset.  \n",
       "1                                                                                                                                                                                                                                                                                               The optional parameters for the `TestShareOfColumnsWithMissingValues` function are `columns`.  \n",
       "2                                                                                                                                                                                                                                                                                                    The purpose of the HuggingFaceModel function is not specified in the provided documents.  \n",
       "3                                                                                                                                  The HuggingFaceToxicityModel function detects hate speech using the HuggingFace model found at https://huggingface.co/facebook/roberta-hate-speech-dynabench-r4-target. It returns a predicted probability for the \"hate\" label, with a scale from 0 to 1.  \n",
       "4                                                                                                                                                                                                                                                                                                                                      The test fails if there is at least one duplicate row.  \n",
       "5                                                                                                                                                                                                                                                                             The `TestShareOfDriftedColumns` function measures the proportion of columns that have drifted between datasets.  \n",
       "6                                                                                                                                                                                                                                                                                                                                                     **Required**: `k`  \\n**Optional**: None  \n",
       "7                                                                                                                                                                                                                                             The `ColumnSummaryMetric` in the `DataQualityPreset` is used to capture summaries for each column, either for all columns or specified columns.  \n",
       "8                                                                                                                                    The drift detection method chooses the appropriate test for each column based on the column type (categorical, numerical, text data, or embeddings), the number of observations in the reference dataset, and the number of unique values in the column.  \n",
       "9  AP@K is calculated by summing the precision at each position up to K where the item is relevant and dividing by the total number of relevant items within K. The formula is:\\n\\n$$\\n\\text{AP@K} = \\frac{1}{N} \\sum_{k=1}^{K} Precision(k) \\times rel(k)\\n$$\\n\\nwhere *N* is the total number of relevant items in K, and *rel(k)* is 1 if the item at position k is relevant, otherwise 0.  "
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "3de32ca3-162f-4ed8-ba88-09a5b9572457",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_colwidth\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "db43a50d-4b1a-4b42-a529-67e85bef0f9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Query</th>\n",
       "      <th>Baseline_answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"How does the TestShareOfColumnsWithMissingValues function determine if a dataset fails the test with reference?</td>\n",
       "      <td>The TestShareOfColumnsWithMissingValues function determines that a dataset fails the test if the number of columns with missing values is higher than in the reference dataset.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What optional parameters can be included in the TestShareOfColumnsWithMissingValues function?</td>\n",
       "      <td>The optional parameters for the `TestShareOfColumnsWithMissingValues` function are `columns`.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is the purpose of the HuggingFaceModel function?</td>\n",
       "      <td>The purpose of the HuggingFaceModel function is not specified in the provided documents.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How does the HuggingFaceToxicityModel function detect hate speech?</td>\n",
       "      <td>The HuggingFaceToxicityModel function detects hate speech using the HuggingFace model found at https://huggingface.co/facebook/roberta-hate-speech-dynabench-r4-target. It returns a predicted probability for the \"hate\" label, with a scale from 0 to 1.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What condition causes the TestNumberOfDuplicatedRows to fail without a reference?</td>\n",
       "      <td>The test fails if there is at least one duplicate row.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>What is measured by the TestShareOfDriftedColumns function?</td>\n",
       "      <td>The `TestShareOfDriftedColumns` function measures the proportion of columns that have drifted between datasets.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>What are the required and optional parameters for the ScoreDistribution function?</td>\n",
       "      <td>**Required**: `k`  \\n**Optional**: None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>What is the role of the ColumnSummaryMetric in the DataQualityPreset?</td>\n",
       "      <td>The `ColumnSummaryMetric` in the `DataQualityPreset` is used to capture summaries for each column, either for all columns or specified columns.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>How does the drift detection method choose the appropriate test for each column?</td>\n",
       "      <td>The drift detection method chooses the appropriate test for each column based on the column type (categorical, numerical, text data, or embeddings), the number of observations in the reference dataset, and the number of unique values in the column.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>How is AP@K calculated in the context of relevant item positions?\"</td>\n",
       "      <td>AP@K is calculated by summing the precision at each position up to K where the item is relevant and dividing by the total number of relevant items within K. The formula is:\\n\\n$$\\n\\text{AP@K} = \\frac{1}{N} \\sum_{k=1}^{K} Precision(k) \\times rel(k)\\n$$\\n\\nwhere *N* is the total number of relevant items in K, and *rel(k)* is 1 if the item at position k is relevant, otherwise 0.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                              Query  \\\n",
       "0  \"How does the TestShareOfColumnsWithMissingValues function determine if a dataset fails the test with reference?   \n",
       "1                     What optional parameters can be included in the TestShareOfColumnsWithMissingValues function?   \n",
       "2                                                             What is the purpose of the HuggingFaceModel function?   \n",
       "3                                                How does the HuggingFaceToxicityModel function detect hate speech?   \n",
       "4                                 What condition causes the TestNumberOfDuplicatedRows to fail without a reference?   \n",
       "5                                                       What is measured by the TestShareOfDriftedColumns function?   \n",
       "6                                 What are the required and optional parameters for the ScoreDistribution function?   \n",
       "7                                             What is the role of the ColumnSummaryMetric in the DataQualityPreset?   \n",
       "8                                  How does the drift detection method choose the appropriate test for each column?   \n",
       "9                                                How is AP@K calculated in the context of relevant item positions?\"   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                             Baseline_answers  \n",
       "0                                                                                                                                                                                                             The TestShareOfColumnsWithMissingValues function determines that a dataset fails the test if the number of columns with missing values is higher than in the reference dataset.  \n",
       "1                                                                                                                                                                                                                                                                                               The optional parameters for the `TestShareOfColumnsWithMissingValues` function are `columns`.  \n",
       "2                                                                                                                                                                                                                                                                                                    The purpose of the HuggingFaceModel function is not specified in the provided documents.  \n",
       "3                                                                                                                                  The HuggingFaceToxicityModel function detects hate speech using the HuggingFace model found at https://huggingface.co/facebook/roberta-hate-speech-dynabench-r4-target. It returns a predicted probability for the \"hate\" label, with a scale from 0 to 1.  \n",
       "4                                                                                                                                                                                                                                                                                                                                      The test fails if there is at least one duplicate row.  \n",
       "5                                                                                                                                                                                                                                                                             The `TestShareOfDriftedColumns` function measures the proportion of columns that have drifted between datasets.  \n",
       "6                                                                                                                                                                                                                                                                                                                                                     **Required**: `k`  \\n**Optional**: None  \n",
       "7                                                                                                                                                                                                                                             The `ColumnSummaryMetric` in the `DataQualityPreset` is used to capture summaries for each column, either for all columns or specified columns.  \n",
       "8                                                                                                                                    The drift detection method chooses the appropriate test for each column based on the column type (categorical, numerical, text data, or embeddings), the number of observations in the reference dataset, and the number of unique values in the column.  \n",
       "9  AP@K is calculated by summing the precision at each position up to K where the item is relevant and dividing by the total number of relevant items within K. The formula is:\\n\\n$$\\n\\text{AP@K} = \\frac{1}{N} \\sum_{k=1}^{K} Precision(k) \\times rel(k)\\n$$\\n\\nwhere *N* is the total number of relevant items in K, and *rel(k)* is 1 if the item at position k is relevant, otherwise 0.  "
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_dataset[[\"Query\", \"Baseline_answers\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8530a6c0-6d4d-4c44-be73-f7d3c7d88e50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
