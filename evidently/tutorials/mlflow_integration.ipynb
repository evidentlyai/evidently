{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using MLFlow and Evidently to Evaluate Data Drift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we will explore the MLflow integration with Evidently.\n",
    "\n",
    "This notebook shows how you can use the Evidently and MLflow to:\n",
    "* calculate data drift for the model, performed as batch checks \n",
    "* log data drift using MLflow Tracking\n",
    "* explore the result using MLflow UI\n",
    "\n",
    "Acknowledgments:\n",
    "* The dataset used in the example is from:  https://www.kaggle.com/c/bike-sharing-demand/data?select=train.csv\n",
    "* Fanaee-T, Hadi, and Gama, Joao, 'Event labeling combining ensemble detectors and background knowledge', Progress in Artificial Intelligence (2013): pp. 1-15, Springer Berlin Heidelberg\n",
    "* More information about the dataset can be found in UCI machine learning repository: https://archive.ics.uci.edu/ml/datasets/bike+sharing+dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting StartedÂ¶\n",
    "To run this tutorial:\n",
    "\n",
    "1. Install MLflow\n",
    "You can install MLflow with the following command `pip install mlflow` or install MLflow with scikit-learn via `pip install mlflow[extras]`\n",
    "More details:https://mlflow.org/docs/latest/tutorials-and-examples/tutorial.html#id5\n",
    "\n",
    "2. Install Evidently\n",
    "You can install Evidently with the following command `pip install evidently`\n",
    "In case you are also interested in Evidently Dashboard visualization in Jupyter install jupyter nbextention:\n",
    "`jupyter nbextension install --sys-prefix --symlink --overwrite --py evidently`\n",
    "And activate it:\n",
    "`jupyter nbextension enable evidently --py --sys-prefix`\n",
    "More details: https://docs.evidentlyai.com/install-evidently \n",
    "\n",
    "3. Load data from https://archive.ics.uci.edu/ml/datasets/bike+sharing+dataset and save in locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import requests\n",
    "import zipfile\n",
    "import io\n",
    "\n",
    "from evidently.model_profile import Profile\n",
    "from evidently.profile_sections import DataDriftProfileSection\n",
    "from evidently.pipeline.column_mapping import ColumnMapping\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.tracking import MlflowClient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More information about the dataset can be found in Kaggle Playground Competition: https://www.kaggle.com/c/bike-sharing-demand/data?select=train.csv\n",
    "\n",
    "Acknowledgement: Fanaee-T, Hadi, and Gama, Joao, 'Event labeling combining ensemble detectors and background knowledge', Progress in Artificial Intelligence (2013): pp. 1-15, Springer Berlin Heidelberg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "content = requests.get(\"https://archive.ics.uci.edu/ml/machine-learning-databases/00275/Bike-Sharing-Dataset.zip\").content\n",
    "with zipfile.ZipFile(io.BytesIO(content)) as arc:\n",
    "    raw_data = pd.read_csv(arc.open(\"day.csv\"), header=0, sep=',', parse_dates=['dteday'], index_col='dteday')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instant</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dteday</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011-01-01</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.344167</td>\n",
       "      <td>0.363625</td>\n",
       "      <td>0.805833</td>\n",
       "      <td>0.160446</td>\n",
       "      <td>331</td>\n",
       "      <td>654</td>\n",
       "      <td>985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-02</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.363478</td>\n",
       "      <td>0.353739</td>\n",
       "      <td>0.696087</td>\n",
       "      <td>0.248539</td>\n",
       "      <td>131</td>\n",
       "      <td>670</td>\n",
       "      <td>801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-03</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.196364</td>\n",
       "      <td>0.189405</td>\n",
       "      <td>0.437273</td>\n",
       "      <td>0.248309</td>\n",
       "      <td>120</td>\n",
       "      <td>1229</td>\n",
       "      <td>1349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-04</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.212122</td>\n",
       "      <td>0.590435</td>\n",
       "      <td>0.160296</td>\n",
       "      <td>108</td>\n",
       "      <td>1454</td>\n",
       "      <td>1562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-05</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.226957</td>\n",
       "      <td>0.229270</td>\n",
       "      <td>0.436957</td>\n",
       "      <td>0.186900</td>\n",
       "      <td>82</td>\n",
       "      <td>1518</td>\n",
       "      <td>1600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            instant  season  yr  mnth  holiday  weekday  workingday  \\\n",
       "dteday                                                                \n",
       "2011-01-01        1       1   0     1        0        6           0   \n",
       "2011-01-02        2       1   0     1        0        0           0   \n",
       "2011-01-03        3       1   0     1        0        1           1   \n",
       "2011-01-04        4       1   0     1        0        2           1   \n",
       "2011-01-05        5       1   0     1        0        3           1   \n",
       "\n",
       "            weathersit      temp     atemp       hum  windspeed  casual  \\\n",
       "dteday                                                                    \n",
       "2011-01-01           2  0.344167  0.363625  0.805833   0.160446     331   \n",
       "2011-01-02           2  0.363478  0.353739  0.696087   0.248539     131   \n",
       "2011-01-03           1  0.196364  0.189405  0.437273   0.248309     120   \n",
       "2011-01-04           1  0.200000  0.212122  0.590435   0.160296     108   \n",
       "2011-01-05           1  0.226957  0.229270  0.436957   0.186900      82   \n",
       "\n",
       "            registered   cnt  \n",
       "dteday                        \n",
       "2011-01-01         654   985  \n",
       "2011-01-02         670   801  \n",
       "2011-01-03        1229  1349  \n",
       "2011-01-04        1454  1562  \n",
       "2011-01-05        1518  1600  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#observe data structure\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set column mapping for Evidently Profile\n",
    "data_columns = ColumnMapping()\n",
    "data_columns.numerical_features = ['weathersit', 'temp', 'atemp', 'hum', 'windspeed']\n",
    "data_columns.categorical_features = ['holiday', 'workingday']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate data drift with Evidently Profile\n",
    "def eval_drift(reference, production, column_mapping):\n",
    "    data_drift_profile = Profile(sections=[DataDriftProfileSection()])\n",
    "    data_drift_profile.calculate(reference, production, column_mapping=column_mapping)\n",
    "    report = data_drift_profile.json()\n",
    "    json_report = json.loads(report)\n",
    "\n",
    "    drifts = []\n",
    "    num_features = column_mapping.numerical_features if column_mapping.numerical_features else []\n",
    "    cat_features = column_mapping.categorical_features if column_mapping.categorical_features else []\n",
    "    \n",
    "    for feature in column_mapping.numerical_features + column_mapping.categorical_features:\n",
    "        drifts.append((feature, json_report['data_drift']['data']['metrics'][feature]['p_value'])) \n",
    "    return drifts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set reference dates\n",
    "reference_dates = ('2011-01-01 00:00:00','2011-01-28 23:00:00')\n",
    "\n",
    "#set experiment batches dates\n",
    "experiment_batches = [\n",
    "    ('2011-01-01 00:00:00','2011-01-29 23:00:00'),\n",
    "    ('2011-01-29 00:00:00','2011-02-07 23:00:00'),\n",
    "    ('2011-02-07 00:00:00','2011-02-14 23:00:00'),\n",
    "    ('2011-02-15 00:00:00','2011-02-21 23:00:00'),  \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: 'Data Drift Evaluation with Evidently' does not exist. Creating a new experiment\n",
      "<RunInfo: artifact_uri='file:///Users/emeli/Dev/evidently_dev/evidently/tutorials/mlruns/1/0edacc2499a842c98f2865d4db4d5e69/artifacts', end_time=None, experiment_id='1', lifecycle_stage='active', run_id='0edacc2499a842c98f2865d4db4d5e69', run_uuid='0edacc2499a842c98f2865d4db4d5e69', start_time=1632492708903, status='RUNNING', user_id='emeli'>\n",
      "<RunInfo: artifact_uri='file:///Users/emeli/Dev/evidently_dev/evidently/tutorials/mlruns/1/39968ca74f8a41cba5366449334f3b94/artifacts', end_time=None, experiment_id='1', lifecycle_stage='active', run_id='39968ca74f8a41cba5366449334f3b94', run_uuid='39968ca74f8a41cba5366449334f3b94', start_time=1632492709376, status='RUNNING', user_id='emeli'>\n",
      "<RunInfo: artifact_uri='file:///Users/emeli/Dev/evidently_dev/evidently/tutorials/mlruns/1/026b744ff6a7457c80098a33ffab576a/artifacts', end_time=None, experiment_id='1', lifecycle_stage='active', run_id='026b744ff6a7457c80098a33ffab576a', run_uuid='026b744ff6a7457c80098a33ffab576a', start_time=1632492710145, status='RUNNING', user_id='emeli'>\n",
      "<RunInfo: artifact_uri='file:///Users/emeli/Dev/evidently_dev/evidently/tutorials/mlruns/1/b8346e871c7b48c4b1b0b7646087d452/artifacts', end_time=None, experiment_id='1', lifecycle_stage='active', run_id='b8346e871c7b48c4b1b0b7646087d452', run_uuid='b8346e871c7b48c4b1b0b7646087d452', start_time=1632492710511, status='RUNNING', user_id='emeli'>\n"
     ]
    }
   ],
   "source": [
    "#log into MLflow\n",
    "client = MlflowClient()\n",
    "\n",
    "#set experiment\n",
    "mlflow.set_experiment('Data Drift Evaluation with Evidently')\n",
    "\n",
    "#start new run\n",
    "for date in experiment_batches:\n",
    "    with mlflow.start_run() as run: #inside brackets run_name='test'\n",
    "        \n",
    "        # Log parameters\n",
    "        mlflow.log_param(\"begin\", date[0])\n",
    "        mlflow.log_param(\"end\", date[1])\n",
    "\n",
    "        # Log metrics\n",
    "        metrics = eval_drift(raw_data.loc[reference_dates[0]:reference_dates[1]], \n",
    "                             raw_data.loc[date[0]:date[1]], \n",
    "                             column_mapping=data_columns)\n",
    "        for feature in metrics:\n",
    "            mlflow.log_metric(feature[0], round(feature[1], 3))\n",
    "\n",
    "        print(run.info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run MLflow UI (it will be more convinient to run it directly from the terminal)\n",
    "!mlflow ui"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
