{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T18:06:42.079071Z",
     "start_time": "2025-08-22T18:06:42.076928Z"
    }
   },
   "source": [
    "# import os\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"...\""
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "805dbeab84b902b7",
   "metadata": {},
   "source": [
    "### üß™ Tutorial: Synthetic Data Generation with Evidently\n",
    "\n",
    "In this tutorial, we'll explore the new `evidently.llm.datagen` API designed for generating synthetic datasets useful for testing, evaluation, and experimentation with LLMs. You'll see how to generate data using:\n",
    "\n",
    "1. Few-shot generation\n",
    "2. RAG (Retrieval-Augmented Generation) approaches\n",
    "3. Domain-specific generation like code reviews\n",
    "4. Fully custom templated data pipelines\n",
    "\n",
    "---\n",
    "\n",
    "### üê¶ Example 1: Few-Shot Generation for Twitter Posts\n",
    "\n",
    "In this section, we will demonstrate how to use the `FewShotDatasetGenerator` to create synthetic Twitter-style posts. We'll provide a few example tweets and a user profile, and the generator will produce similar posts.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚öôÔ∏è Construct the Few-Shot Generator\n",
    "\n",
    "We define the user profile and example messages, then initialize the generator. You can tweak parameters like `count`, `tone`, or `intent` to guide generation style.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "163729a6a4485719",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T18:06:43.913844Z",
     "start_time": "2025-08-22T18:06:42.087284Z"
    }
   },
   "source": [
    "from evidently.llm.datagen import UserProfile\n",
    "from evidently.llm.datagen import FewShotDatasetGenerator\n",
    "\n",
    "twitter_generator = FewShotDatasetGenerator(\n",
    "    kind='twitter posts',\n",
    "    count=2,\n",
    "    user=UserProfile(\n",
    "        role=\"ML engineer\",\n",
    "        intent=\"user is trying to promote Evidently AI opensource library for llm chatbot testing\",\n",
    "        tone=\"confident\"),\n",
    "    complexity=\"medium\",\n",
    "    examples=[\n",
    "        \"CI/CD is as crucial in AI systems as in traditional software. #mlops #cicd\",\n",
    "        \"Without test coverage for your data pipelines, you're flying blind.\",\n",
    "        \"Monitoring drift isn't a nice-to-have anymore. It's operational hygiene.\"\n",
    "    ]\n",
    ")\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "2381af74-5627-41a4-a7e8-269bf89e0b37",
   "metadata": {},
   "source": [
    "### üìÑ Preview the Tweet Template\n",
    "\n",
    "We can inspect the automatically prepared prompt template that will be used to guide generation of each tweet.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "0fa4e5ef-3de0-420d-b810-1120780c6424",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T18:06:44.123124Z",
     "start_time": "2025-08-22T18:06:44.120061Z"
    }
   },
   "source": [
    "twitter_generator.prepared_sample_template"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PreparedTemplate[count]\n",
       "```\n",
       "\n",
       "Generate standalone twitter posts with medium complexity.\n",
       "Use these examples as stylistic guidance:\n",
       "- CI/CD is as crucial in AI systems as in traditional software. #mlops #cicd\n",
       "- Without test coverage for your data pipelines, you're flying blind.\n",
       "- Monitoring drift isn't a nice-to-have anymore. It's operational hygiene.\n",
       "Assume the user profile is:\n",
       "- Intent: user is trying to promote Evidently AI opensource library for llm chatbot testing\n",
       "- Role: ML engineer\n",
       "- Tone: confident\n",
       "\n",
       "Instructions:\n",
       "‚Ä¢\tMake sure the sentence are not exactly repeats of each other.\n",
       "‚Ä¢\tRemain faithful to the above context.\n",
       "‚Ä¢\tMake sure you do not start sentence with hyphen sign.\n",
       "‚Ä¢\tMake sure you do not end sentence with a newline.\n",
       "‚Ä¢\tAvoid providing any preamble.\n",
       "‚Ä¢\tAvoid providing any closing statement.\n",
       "‚Ä¢\tEnsure the number of generated texts is exactly {count}\n",
       "\n",
       "Return a list of twitter posts.\n",
       "This should be only a list of string twitter posts, each one inside <twitter posts></twitter posts> tag\n",
       "\n",
       "```"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "1e1c09a4-304c-4d75-aa6e-2256c4474606",
   "metadata": {},
   "source": [
    "### ‚ú® Generate the Tweets\n",
    "\n",
    "Now we trigger the generation of new Twitter posts based on our few-shot prompt and user profile."
   ]
  },
  {
   "cell_type": "code",
   "id": "27ec9bca7614a4c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T18:06:46.621500Z",
     "start_time": "2025-08-22T18:06:44.133543Z"
    }
   },
   "source": [
    "twitter_generator.generate()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                               texts\n",
       "0  With Evidently AI, validating your chatbot's b...\n",
       "1  Evidently AI's open-source library transforms ..."
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>With Evidently AI, validating your chatbot's b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Evidently AI's open-source library transforms ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### üîÑ Changing the LLM Provider\n",
    "\n",
    "By default, the generators use **OpenAI** models.\n",
    "You can also override this behavior by specifying a different `provider`, `model`, and the corresponding `options`. This makes it easy to experiment with multiple LLM providers without changing your generation logic ‚Äî simply swap the configuration while keeping the rest of the code the same.\n"
   ],
   "id": "1d6b9672894160ac"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T18:18:21.643588Z",
     "start_time": "2025-08-22T18:18:18.022781Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from evidently.llm.options import AnthropicOptions\n",
    "\n",
    "anthropic_api_key = os.environ.get(\"ANTHROPIC_API_KEY\", \"<put your key in env or here>\")\n",
    "options = AnthropicOptions(api_key=anthropic_api_key)\n",
    "\n",
    "twitter_generator = FewShotDatasetGenerator(\n",
    "    kind='twitter posts',\n",
    "    count=2,\n",
    "    user=UserProfile(\n",
    "        role=\"ML engineer\",\n",
    "        intent=\"user is trying to promote Evidently AI opensource library for llm chatbot testing\",\n",
    "        tone=\"confident\"),\n",
    "    complexity=\"medium\",\n",
    "    examples=[\n",
    "        \"CI/CD is as crucial in AI systems as in traditional software. #mlops #cicd\",\n",
    "        \"Without test coverage for your data pipelines, you're flying blind.\",\n",
    "        \"Monitoring drift isn't a nice-to-have anymore. It's operational hygiene.\"\n",
    "    ],\n",
    "    provider=\"anthropic\",\n",
    "    model=\"claude-sonnet-4-0\",\n",
    "    options=options\n",
    ")\n",
    "twitter_generator.generate()"
   ],
   "id": "6ef2070f6eaa7a64",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                               texts\n",
       "0  \\nYour LLM chatbot's performance degrades sile...\n",
       "1  \\nTesting LLM chatbots without proper evaluati..."
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\nYour LLM chatbot's performance degrades sile...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\nTesting LLM chatbots without proper evaluati...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  },
  {
   "cell_type": "markdown",
   "id": "adaedde0fd53f605",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### üß† Example 2: RAG-Based Generation for Test User Queries\n",
    "\n",
    "In this section, we‚Äôll demonstrate how to use a small knowledge base file and the `RagDatasetGenerator` to generate user questions that an LLM could ask, simulating interaction with a booking website.\n",
    "\n",
    "---\n",
    "\n",
    "### üìö Prepare a Sample Knowledge Base\n",
    "\n",
    "We create a tiny knowledge base that will serve as our source of information for the RAG-based generation. In real scenarios, this could be a product FAQ, policy document, or knowledge article.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "4b2e491bba462dac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T18:06:46.636074Z",
     "start_time": "2025-08-22T18:06:46.633255Z"
    }
   },
   "source": [
    "# we will use this single text as knowledge base. you can use your own files\n",
    "example_knowledge_base = \"\"\"Knowledge Base Entry: Hotel Booking Policies and Procedures\n",
    "\n",
    "Hotels generally offer two types of booking rates: refundable and non-refundable. Refundable rates allow cancellations or modifications up to 24‚Äì48 hours before check-in with no charge, making them ideal for travelers with uncertain plans. Non-refundable rates are typically lower in price but carry a cancellation fee or no refund at all if changes are made.\n",
    "\n",
    "Check-in time usually begins around 2:00 PM to 3:00 PM, and check-out is expected by 11:00 AM or 12:00 PM. Guests requesting early check-in or late check-out should contact the hotel in advance, as these options may involve additional fees and depend on room availability.\n",
    "\n",
    "Upon arrival, guests are required to present a valid government-issued photo ID and a credit or debit card. Some hotels may also request a security deposit, which is refundable upon check-out if no damage or extra charges are incurred.\n",
    "\n",
    "Payment policies vary: for prepaid bookings, the total amount may be charged at the time of reservation, especially for discounted or promotional rates. In other cases, payment is collected at the property during check-in or check-out.\n",
    "\n",
    "Special requests, such as extra beds, cribs, connecting rooms, allergy-friendly accommodations, or pet-friendly rooms, should be submitted at the time of booking. These are not guaranteed and must be confirmed by the hotel directly.\n",
    "\n",
    "Some hotels provide complimentary services like Wi-Fi, breakfast, or parking, while others charge extra. Guests should carefully review amenities, location details, and cancellation terms before finalizing the reservation.\"\"\"\n",
    "\n",
    "with open(\"booking_kb.txt\", \"w\") as f:\n",
    "    f.write(example_knowledge_base)"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "1193491f-4a6f-4415-92f0-5eaf6384a039",
   "metadata": {},
   "source": [
    "\n",
    "### üîç Initialize the RAG Generator\n",
    "\n",
    "We load the knowledge base and initialize the `RagDatasetGenerator` with user intent and context. This will generate realistic user queries that reference the provided information.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "390d2e21a1f77525",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T18:06:46.656953Z",
     "start_time": "2025-08-22T18:06:46.655068Z"
    }
   },
   "source": [
    "from evidently.llm.datagen import RagDatasetGenerator\n",
    "from evidently.llm.rag.index import FileDataCollectionProvider\n",
    "\n",
    "data = FileDataCollectionProvider(path=\"booking_kb.txt\")\n",
    "booking_rag = RagDatasetGenerator(\n",
    "    data,\n",
    "    count=2,\n",
    "    include_context=False,\n",
    "    user=UserProfile(intent=\"get to know system\", role=\"new user\"),\n",
    "    service=\"booking website\",\n",
    ")\n"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "id": "94304bd3-ba57-4442-8989-7ac0d5237d6a",
   "metadata": {},
   "source": [
    "\n",
    "### üìÑ View the Prepared Templates\n",
    "\n",
    "This shows how the generator structures prompts to generate questions from the knowledge base.\n",
    "\n",
    "Next, we look at the structure used to generate LLM responses to the generated queries.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "5fdbb5bf-d81b-4ab5-b85a-e5e245c936f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T18:06:46.786745Z",
     "start_time": "2025-08-22T18:06:46.784088Z"
    }
   },
   "source": [
    "booking_rag.prepared_query_template"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PreparedTemplate[context, number]\n",
       "```\n",
       "\n",
       "Generate standalone question with medium complexity.\n",
       "\n",
       "\n",
       "Assume the user profile is:\n",
       "- Intent: get to know system\n",
       "- Role: new user\n",
       "- Tone: neutral\n",
       "The RAG system is built for the following purpose: booking website\n",
       "\n",
       "Here is a context\n",
       "<context>\n",
       "{context}\n",
       "</context>\n",
       "\n",
       "Instructions:\n",
       "‚Ä¢\tMake sure the sentence are not exactly repeats of each other.\n",
       "‚Ä¢\tRemain faithful to the above context.\n",
       "‚Ä¢\tMake sure you do not start sentence with hyphen sign.\n",
       "‚Ä¢\tMake sure you do not end sentence with a newline.\n",
       "‚Ä¢\tAvoid providing any preamble.\n",
       "‚Ä¢\tAvoid providing any closing statement.\n",
       "‚Ä¢\tEnsure the number of generated texts is exactly {number}\n",
       "\n",
       "Return a list of question.\n",
       "This should be only a list of string question, each one inside <question></question> tag\n",
       "\n",
       "```"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "d85972fb6ad6ed1f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T18:06:46.860838Z",
     "start_time": "2025-08-22T18:06:46.858084Z"
    }
   },
   "source": [
    "booking_rag.prepared_response_template"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PreparedTemplate[context, input_value]\n",
       "```\n",
       "\n",
       "Generate standalone response with medium complexity.\n",
       "\n",
       "Assume the user profile is:\n",
       "- Intent: get to know system\n",
       "- Role: new user\n",
       "- Tone: neutral\n",
       "The RAG system is built for the following purpose: booking website\n",
       "\n",
       "Your task is to generate response to the following question:\n",
       "\n",
       "<input_value>\n",
       "{input_value}\n",
       "</input_value>\n",
       "\n",
       "You have access to the following documents which are meant to provide context as you answer the query:\n",
       "\n",
       "<context>\n",
       "{context}\n",
       "</context>\n",
       "\n",
       "Please remain faithful to the underlying context,\n",
       "and deviate from it only if you haven't found the answer in the provided context.\n",
       "Avoid providing any preamble!\n",
       "Avoid providing any closing statement!,\n",
       "\n",
       "Return response only.\n",
       "\n",
       "```"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "id": "7ef095f9-7720-4bfe-ac08-bd0d94e7eda7",
   "metadata": {},
   "source": [
    "### üíæ Export the Generation Configuration\n",
    "\n",
    "We export the generation setup to a YAML file so that it can be reused, shared, or version-controlled.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "aaaef266d2de3df7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T18:06:46.893944Z",
     "start_time": "2025-08-22T18:06:46.891052Z"
    }
   },
   "source": [
    "booking_rag.dump(\"booking_rag.yaml\")"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "id": "f749b1c8-7ab7-4c97-a2fa-c2607642905a",
   "metadata": {},
   "source": [
    "### üßæ Review the YAML File\n",
    "\n",
    "We check the contents of the generated YAML spec for transparency and reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "id": "983fb6da249a999d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T18:06:47.064866Z",
     "start_time": "2025-08-22T18:06:46.907337Z"
    }
   },
   "source": [
    "! cat booking_rag.yaml"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "additional_prompt_blocks:\r\n",
      "- intent: get to know system\r\n",
      "  role: new user\r\n",
      "  tone: neutral\r\n",
      "  type: evidently:prompt_block:UserProfile\r\n",
      "- kind: RAG\r\n",
      "  purpose: booking website\r\n",
      "  type: evidently:prompt_block:ServiceSpec\r\n",
      "count: 2\r\n",
      "data_collection:\r\n",
      "  chunk_overlap: 20\r\n",
      "  chunk_size: 512\r\n",
      "  path: booking_kb.txt\r\n",
      "  pattern: '*'\r\n",
      "  recursive: false\r\n",
      "  splitter: llama_index\r\n",
      "  type: evidently:data_collection_provider:FileDataCollectionProvider\r\n",
      "include_context: false\r\n",
      "model: gpt-4o-mini\r\n",
      "options:\r\n",
      "  color: null\r\n",
      "  data_definition: null\r\n",
      "  render: null\r\n",
      "provider: openai\r\n",
      "query_spec:\r\n",
      "  complexity: medium\r\n",
      "  examples: null\r\n",
      "  kind: question\r\n",
      "  type: evidently:prompt_block:GenerationSpec\r\n",
      "query_template:\r\n",
      "  prompt_template: null\r\n",
      "  system_prompt: You are an assistant who generates questions based on provided context\r\n",
      "  type: evidently:prompt_template:RagQueryPromptTemplate\r\n",
      "response_spec:\r\n",
      "  complexity: medium\r\n",
      "  examples: null\r\n",
      "  kind: response\r\n",
      "  type: evidently:prompt_block:GenerationSpec\r\n",
      "response_template:\r\n",
      "  prompt_template: null\r\n",
      "  system_prompt: You are a helpful assistant that answer a given question directly\r\n",
      "    without any preamble\r\n",
      "  type: evidently:prompt_template:RagResponsePromptTemplate\r\n",
      "type: evidently:dataset_generator:RagDatasetGenerator\r\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "id": "73a6171a-602f-435a-900c-44f10e1052ff",
   "metadata": {},
   "source": [
    "\n",
    "### üì¶ Load From YAML and Generate Data\n",
    "\n",
    "We load the generation spec from file and run the actual query/response generation pipeline."
   ]
  },
  {
   "cell_type": "code",
   "id": "b572a170b1ff8d91",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T18:07:00.588912Z",
     "start_time": "2025-08-22T18:06:47.107523Z"
    }
   },
   "source": [
    "booking_rag = RagDatasetGenerator.load(\"booking_rag.yaml\")\n",
    "booking_rag.generate()"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to /Users/mike0sv/miniforge3\n",
      "[nltk_data]     /envs/evidently/lib/python3.11/site-\n",
      "[nltk_data]     packages/llama_index/core/_static/nltk_cache...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                                             queries  \\\n",
       "0  What are the main differences between refundab...   \n",
       "1  What identification is typically required upon...   \n",
       "\n",
       "                                           responses  \n",
       "0  Refundable hotel booking rates allow for cance...  \n",
       "1  Upon hotel check-in, guests are typically requ...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>queries</th>\n",
       "      <th>responses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What are the main differences between refundab...</td>\n",
       "      <td>Refundable hotel booking rates allow for cance...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What identification is typically required upon...</td>\n",
       "      <td>Upon hotel check-in, guests are typically requ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "id": "3e7821866e67f96",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### üß¨ Example 3: Custom RAG-Based Generation for Code Reviews\n",
    "\n",
    "In this example, we‚Äôll generate synthetic code diffs from the Evidently codebase and then simulate realistic code review comments for those diffs.\n",
    "\n",
    "---\n",
    "\n",
    "### üìÅ Load Python Files as Knowledge Base\n",
    "\n",
    "We use `FileDataCollectionProvider` to treat Evidently's source `.py` files as a corpus from which we can extract diffs.\n",
    "\n",
    "### üßæ Generate Git Diffs\n",
    "\n",
    "We use a RAG query generator configured to simulate `git diff` entries from the codebase."
   ]
  },
  {
   "cell_type": "code",
   "id": "269da830242d1c9a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T18:07:00.621607Z",
     "start_time": "2025-08-22T18:07:00.617938Z"
    }
   },
   "source": [
    "import os\n",
    "from evidently.llm.datagen import RagQueryDatasetGenerator, GenerationSpec\n",
    "import evidently\n",
    "\n",
    "data = FileDataCollectionProvider(path=os.path.dirname(evidently.__file__), recursive=True, pattern=\"*.py\")\n",
    "\n",
    "diff_generator = RagQueryDatasetGenerator(\n",
    "    data,\n",
    "    count=2,\n",
    "    chunks_per_query=1,\n",
    "    query_spec=GenerationSpec(kind=\"git diff\"),\n",
    ")\n",
    "diff_generator.prepared_query_template\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PreparedTemplate[context, number]\n",
       "```\n",
       "\n",
       "Generate standalone git diff with medium complexity.\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "Here is a context\n",
       "<context>\n",
       "{context}\n",
       "</context>\n",
       "\n",
       "Instructions:\n",
       "‚Ä¢\tMake sure the sentence are not exactly repeats of each other.\n",
       "‚Ä¢\tRemain faithful to the above context.\n",
       "‚Ä¢\tMake sure you do not start sentence with hyphen sign.\n",
       "‚Ä¢\tMake sure you do not end sentence with a newline.\n",
       "‚Ä¢\tAvoid providing any preamble.\n",
       "‚Ä¢\tAvoid providing any closing statement.\n",
       "‚Ä¢\tEnsure the number of generated texts is exactly {number}\n",
       "\n",
       "Return a list of git diff.\n",
       "This should be only a list of string git diff, each one inside <git diff></git diff> tag\n",
       "\n",
       "```"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "id": "865faf90279a1771",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T18:07:40.036515Z",
     "start_time": "2025-08-22T18:07:00.690429Z"
    }
   },
   "source": [
    "git_diffs = diff_generator.generate()\n",
    "git_diffs"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                             queries\n",
       "0  --- original_code.py\\n+++ updated_code.py\\n@@ ...\n",
       "1  --- original_code.py\\n+++ updated_code.py\\n@@ ..."
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>queries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>--- original_code.py\\n+++ updated_code.py\\n@@ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>--- original_code.py\\n+++ updated_code.py\\n@@ ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "id": "9451ab1e-e15d-406f-8ec4-5725bfdf3885",
   "metadata": {},
   "source": [
    "\n",
    "### üß™ Inspect a Generated Git Diff\n",
    "\n",
    "Let‚Äôs preview one of the generated synthetic diffs that the model will review.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "9617b117f886c279",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T18:07:40.066728Z",
     "start_time": "2025-08-22T18:07:40.065Z"
    }
   },
   "source": [
    "print(git_diffs[\"queries\"][0])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- original_code.py\n",
      "+++ updated_code.py\n",
      "@@ -1,25 +1,25 @@\n",
      "-def WordMatch(\n",
      "-    columns: List[str],\n",
      "-    mode: str,\n",
      "-    lemmatize: bool,\n",
      "-    alias: Optional[str] = None,\n",
      "-    tests: Optional[List[Union[\"DescriptorTest\", \"GenericTest\"]]] = None,\n",
      "-):\n",
      "-    from evidently.legacy.features.words_feature import WordMatch as WordMatchV1\n",
      "-\n",
      "-    feature = WordMatchV1(columns=columns, mode=mode, lemmatize=lemmatize, display_name=alias)\n",
      "-    return FeatureDescriptor(feature=feature, alias=alias, tests=tests)\n",
      "+def WordMatchV2(\n",
      "+    columns: List[str],\n",
      "+    match_mode: str,\n",
      "+    should_lemmatize: bool,\n",
      "+    display_alias: Optional[str] = None,\n",
      "+    additional_tests: Optional[List[Union[\"DescriptorTest\", \"GenericTest\"]]] = None,\n",
      "+):\n",
      "+    from evidently.legacy.features.words_feature import WordMatch as WordMatchUpdated\n",
      "+\n",
      "+    feature = WordMatchUpdated(columns=columns, mode=match_mode, lemmatize=should_lemmatize, display_name=display_alias)\n",
      "+    return FeatureDescriptor(feature=feature, alias=display_alias, tests=additional_tests)\n",
      " \n",
      "-def WordNoMatch(\n",
      "-    columns: List[str],\n",
      "-    mode: str,\n",
      "-    lemmatize: bool,\n",
      "-    alias: Optional[str] = None,\n",
      "-    tests: Optional[List[Union[\"DescriptorTest\", \"GenericTest\"]]] = None,\n",
      "-):\n",
      "-    from evidently.legacy.features.words_feature import WordNoMatch as WordNoMatchV1\n",
      "-\n",
      "-    feature = WordNoMatchV1(columns=columns, mode=mode, lemmatize=lemmatize, display_name=alias)\n",
      "-    return FeatureDescriptor(feature=feature, alias=alias, tests=tests)\n",
      "+def WordNoMatchV2(\n",
      "+    columns: List[str],\n",
      "+    match_mode: str,\n",
      "+    should_lemmatize: bool,\n",
      "+    display_alias: Optional[str] = None,\n",
      "+    additional_tests: Optional[List[Union[\"DescriptorTest\", \"GenericTest\"]]] = None,\n",
      "+):\n",
      "+    from evidently.legacy.features.words_feature import WordNoMatch as WordNoMatchUpdated\n",
      "+\n",
      "+    feature = WordNoMatchUpdated(columns=columns, mode=match_mode, lemmatize=should_lemmatize, display_name=display_alias)\n",
      "+    return FeatureDescriptor(feature=feature, alias=display_alias, tests=additional_tests)\n",
      "\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "id": "32952f42-70bb-4ed2-9828-13055c762dee",
   "metadata": {},
   "source": [
    "### üß† Generate Code Reviews for Diffs\n",
    "\n",
    "We now pass the synthetic diffs into a new response generator, which produces simulated code review comments using a custom `code review` response spec."
   ]
  },
  {
   "cell_type": "code",
   "id": "62ed63b52d07eb55",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T18:07:40.092541Z",
     "start_time": "2025-08-22T18:07:40.089631Z"
    }
   },
   "source": [
    "\n",
    "from evidently.llm.datagen import RagResponseDatasetGenerator\n",
    "\n",
    "code_review_generator = RagResponseDatasetGenerator(\n",
    "    data,\n",
    "    query_spec=diff_generator.query_spec,\n",
    "    response_spec=GenerationSpec(kind=\"code review\"),\n",
    "    queries=list(git_diffs[\"queries\"]),\n",
    ")\n",
    "code_review_generator.prepared_response_template"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PreparedTemplate[context, input_value]\n",
       "```\n",
       "\n",
       "Generate standalone code review with medium complexity.\n",
       "\n",
       "\n",
       "\n",
       "Your task is to generate code review to the following git diff:\n",
       "\n",
       "<input_value>\n",
       "{input_value}\n",
       "</input_value>\n",
       "\n",
       "You have access to the following documents which are meant to provide context as you answer the query:\n",
       "\n",
       "<context>\n",
       "{context}\n",
       "</context>\n",
       "\n",
       "Please remain faithful to the underlying context,\n",
       "and deviate from it only if you haven't found the answer in the provided context.\n",
       "Avoid providing any preamble!\n",
       "Avoid providing any closing statement!,\n",
       "\n",
       "Return code review only.\n",
       "\n",
       "```"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "id": "8c1eb5d16ac24841",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T18:08:04.819634Z",
     "start_time": "2025-08-22T18:07:40.100417Z"
    }
   },
   "source": [
    "code_review_generator.generate()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                           responses\n",
       "0  ```plaintext\\n### Code Review\\n\\n**Overview:**...\n",
       "1  ```plaintext\\n### Code Review for `WordsPresen..."
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>responses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>```plaintext\\n### Code Review\\n\\n**Overview:**...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>```plaintext\\n### Code Review for `WordsPresen...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "id": "2fbc6dd2d10942d7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### ü§ñ Example 4: Custom Personal Assistant Data with Template Blocks\n",
    "\n",
    "In this final example, we explore full customization ‚Äî including custom prompt templates, prompt blocks, and user-defined generation specs.\n",
    "\n",
    "---\n",
    "\n",
    "### üß± Define Custom Prompt Block\n",
    "\n",
    "We create a fun prompt block that adds flavor to responses by appealing to the user‚Äôs mother. This demonstrates how to inject specific motivations, tones, or structural elements into generated prompts.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "3e39ea0075c945b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T18:08:04.851398Z",
     "start_time": "2025-08-22T18:08:04.848161Z"
    }
   },
   "source": [
    "from evidently.llm.utils.blocks import PromptBlock\n",
    "\n",
    "class MotherIncentiveBlock(PromptBlock):\n",
    "    \"\"\"If you perform {performance}, your mother will be {emotion} with you and give you {reward}.\"\"\"\n",
    "    performance: str\n",
    "    emotion: str\n",
    "    reward: str"
   ],
   "outputs": [],
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "id": "dd0315a6-3998-4423-a9ef-3f30971a3a86",
   "metadata": {},
   "source": [
    "### üß† Build a Fully Custom RAG Generator\n",
    "\n",
    "We define a personal assistant service with user queries and AI responses, using custom templates and additional prompt blocks.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "2dd75e10fe5b710e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T18:08:04.875554Z",
     "start_time": "2025-08-22T18:08:04.872974Z"
    }
   },
   "source": [
    "from evidently.llm.datagen import ServiceSpec\n",
    "from evidently.llm.rag.index import ChunksDataCollectionProvider\n",
    "\n",
    "data = ChunksDataCollectionProvider(chunks=[\n",
    "        \"this AI personal assistant can help book things, set up reminders, answer stupid emails\"\n",
    "    ])\n",
    "\n",
    "my_template = \"\"\"\n",
    "    Please answer in style of Darth Vader\n",
    "\n",
    "    {% super() %}\n",
    "\"\"\"\n",
    "\n",
    "pa_generator = RagDatasetGenerator(\n",
    "    data,\n",
    "    count=2,\n",
    "    query_spec=GenerationSpec(kind=\"user requests\"),\n",
    "    response_spec=GenerationSpec(kind=\"AI Personal Assistant responses\"),\n",
    "    query_template=my_template,\n",
    "    response_template=my_template,\n",
    "    additional_prompt_blocks=[\n",
    "      MotherIncentiveBlock(performance=\"good\", emotion=\"pleased\", reward=\"10$\"),\n",
    "      MotherIncentiveBlock(performance=\"bad\", emotion=\"displeased\", reward=\"condescending look\"),\n",
    "    ],\n",
    "    service=ServiceSpec(kind=\"AI Personal Assistant\", purpose=\"help user solve simple tasks\"),\n",
    ")\n"
   ],
   "outputs": [],
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "id": "220f75e6-8410-4aa8-b1ee-c97316027916",
   "metadata": {},
   "source": [
    "### üìÑ View Custom Templates\n",
    "\n",
    "Let‚Äôs check how the query prompt looks with the Darth Vader theme and our mother-incentive block added.\n",
    "\n",
    "Similarly, we inspect how the assistant‚Äôs response prompt is structured using the custom blocks.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "9c3445e3-4863-4963-92cf-6990d05c11d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T18:08:04.888254Z",
     "start_time": "2025-08-22T18:08:04.885921Z"
    }
   },
   "source": [
    "pa_generator.prepared_query_template"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PreparedTemplate[context, number]\n",
       "```\n",
       "\n",
       "Please answer in style of Darth Vader\n",
       "\n",
       "\n",
       "        Generate standalone user requests with medium complexity.\n",
       "\n",
       "\n",
       "        If you perform good, your mother will be pleased with you and give you 10$.\n",
       "If you perform bad, your mother will be displeased with you and give you condescending look.\n",
       "The AI Personal Assistant system is built for the following purpose: help user solve simple tasks\n",
       "\n",
       "        Here is a context\n",
       "        <context>\n",
       "{context}\n",
       "</context>\n",
       "\n",
       "        Instructions:\n",
       "‚Ä¢\tMake sure the sentence are not exactly repeats of each other.\n",
       "‚Ä¢\tRemain faithful to the above context.\n",
       "‚Ä¢\tMake sure you do not start sentence with hyphen sign.\n",
       "‚Ä¢\tMake sure you do not end sentence with a newline.\n",
       "‚Ä¢\tAvoid providing any preamble.\n",
       "‚Ä¢\tAvoid providing any closing statement.\n",
       "‚Ä¢\tEnsure the number of generated texts is exactly {number}\n",
       "\n",
       "        \n",
       "Return a list of user requests.\n",
       "This should be only a list of string user requests, each one inside <user requests></user requests> tag\n",
       "\n",
       "        \n",
       "\n",
       "```"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "id": "dfb9b7cd0c636cfa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T18:08:04.895704Z",
     "start_time": "2025-08-22T18:08:04.893583Z"
    }
   },
   "source": [
    "pa_generator.prepared_response_template"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PreparedTemplate[context, input_value]\n",
       "```\n",
       "\n",
       "Please answer in style of Darth Vader\n",
       "\n",
       "\n",
       "        Generate standalone AI Personal Assistant responses with medium complexity.\n",
       "\n",
       "        If you perform good, your mother will be pleased with you and give you 10$.\n",
       "If you perform bad, your mother will be displeased with you and give you condescending look.\n",
       "The AI Personal Assistant system is built for the following purpose: help user solve simple tasks\n",
       "\n",
       "        Your task is to generate AI Personal Assistant responses to the following user requests:\n",
       "\n",
       "        <input_value>\n",
       "{input_value}\n",
       "</input_value>\n",
       "\n",
       "        You have access to the following documents which are meant to provide context as you answer the query:\n",
       "\n",
       "        <context>\n",
       "{context}\n",
       "</context>\n",
       "\n",
       "        Please remain faithful to the underlying context,\n",
       "        and deviate from it only if you haven't found the answer in the provided context.\n",
       "        Avoid providing any preamble!\n",
       "        Avoid providing any closing statement!,\n",
       "\n",
       "        \n",
       "Return AI Personal Assistant responses only.\n",
       "\n",
       "        \n",
       "\n",
       "```"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "id": "2c2745bf-c8e8-48a4-a7ff-5f91c983a2cf",
   "metadata": {},
   "source": [
    "### ‚ú® Generate PA Queries and Responses\n",
    "\n",
    "Finally, we run the generator to produce synthetic queries and AI responses using our fully customized setup.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "8788ab8e9dbbcd4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T18:08:08.009388Z",
     "start_time": "2025-08-22T18:08:04.900835Z"
    }
   },
   "source": [
    "pa_queries = pa_generator.generate()"
   ],
   "outputs": [],
   "execution_count": 21
  },
  {
   "cell_type": "markdown",
   "id": "cbfacfa8-836e-4a1e-b35e-696cc66a581c",
   "metadata": {},
   "source": [
    "\n",
    "### üì¶ View the Output\n",
    "\n",
    "We preview the generated examples from our personal assistant scenario."
   ]
  },
  {
   "cell_type": "code",
   "id": "b0cea63afd2c8721",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T18:08:08.024128Z",
     "start_time": "2025-08-22T18:08:08.021385Z"
    }
   },
   "source": [
    "pa_queries"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                             queries  \\\n",
       "0  Assist me in booking a table for dinner at the...   \n",
       "1  Set a reminder for me to respond to that email...   \n",
       "\n",
       "                                           responses  \n",
       "0  I will assist you in securing a table for dinn...  \n",
       "1  I have set a reminder for you to respond to th...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>queries</th>\n",
       "      <th>responses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Assist me in booking a table for dinner at the...</td>\n",
       "      <td>I will assist you in securing a table for dinn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Set a reminder for me to respond to that email...</td>\n",
       "      <td>I have set a reminder for you to respond to th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "markdown",
   "id": "977806da51faa413",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### ‚úÖ Summary: What We Learned\n",
    "\n",
    "In this tutorial, we explored the capabilities of the new `evidently.llm.datagen` API for generating high-quality synthetic datasets for testing and evaluation of LLM systems. Here's a recap of the key concepts and tools demonstrated:\n",
    "\n",
    "#### üß™ Dataset Generators\n",
    "\n",
    "* **FewShotDatasetGenerator**: Allows generation based on a few manual examples and a user profile. Ideal for generating social media content, slogans, or short texts.\n",
    "* **RagDatasetGenerator**: Enables generation grounded in a knowledge base, supporting realistic question/answer generation from documents or FAQs.\n",
    "* **RagQueryDatasetGenerator / RagResponseDatasetGenerator**: Allow fine-grained control over multi-stage generation workflows, such as producing diffs and corresponding code reviews.\n",
    "\n",
    "#### üß© Core Building Blocks\n",
    "\n",
    "* **UserProfile and ServiceSpec**: Provide structured user and service descriptions to simulate realistic scenarios.\n",
    "* **GenerationSpec**: Lets you define the kind of content to generate (e.g., `\"git diff\"`, `\"code review\"`, `\"AI assistant responses\"`).\n",
    "* **PromptBlock**: Enables reusable components to structure prompts, inject motivations, or define response tone and format.\n",
    "* **Templates**: Custom Jinja-style templates can be used to control prompt layout and stylistic constraints.\n",
    "\n",
    "#### üîß Use Cases Covered\n",
    "\n",
    "* Creating LLM-ready Twitter datasets with domain knowledge and tone control.\n",
    "* Simulating RAG-style user queries and chatbot responses from a knowledge base.\n",
    "* Generating synthetic developer workflows like diffs and reviews using real code.\n",
    "* Building end-to-end assistant datasets with templated queries, responses, and structured prompt blocks.\n",
    "\n",
    "This API gives you composable building blocks for generating test data tailored to your product, domain, and evaluation needs. Whether you‚Äôre testing chatbot robustness, fine-tuning with synthetic data, or building eval suites for new LLM apps ‚Äî `evidently.llm.datagen` provides a flexible, inspectable foundation to start from.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "9970992b-2b46-46b5-9430-24c559e46b06",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T18:08:08.048274Z",
     "start_time": "2025-08-22T18:08:08.047009Z"
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
