{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca22d8c-7cd2-4b96-b171-f34b0da30fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805dbeab84b902b7",
   "metadata": {},
   "source": [
    "### üß™ Tutorial: Synthetic Data Generation with Evidently\n",
    "\n",
    "In this tutorial, we'll explore the new `evidently.llm.datagen` API designed for generating synthetic datasets useful for testing, evaluation, and experimentation with LLMs. You'll see how to generate data using:\n",
    "\n",
    "1. Few-shot generation\n",
    "2. RAG (Retrieval-Augmented Generation) approaches\n",
    "3. Domain-specific generation like code reviews\n",
    "4. Fully custom templated data pipelines\n",
    "\n",
    "---\n",
    "\n",
    "### üê¶ Example 1: Few-Shot Generation for Twitter Posts\n",
    "\n",
    "In this section, we will demonstrate how to use the `FewShotDatasetGenerator` to create synthetic Twitter-style posts. We'll provide a few example tweets and a user profile, and the generator will produce similar posts.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚öôÔ∏è Construct the Few-Shot Generator\n",
    "\n",
    "We define the user profile and example messages, then initialize the generator. You can tweak parameters like `count`, `tone`, or `intent` to guide generation style.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163729a6a4485719",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evidently.llm.datagen import UserProfile\n",
    "from evidently.llm.datagen import FewShotDatasetGenerator\n",
    "\n",
    "twitter_generator = FewShotDatasetGenerator(\n",
    "    kind='twitter posts',\n",
    "    count=2,\n",
    "    user=UserProfile(\n",
    "        role=\"ML engineer\",\n",
    "        intent=\"user is trying to promote Evidently AI opensource library for llm chatbot testing\",\n",
    "        tone=\"confident\"),\n",
    "    complexity=\"medium\",\n",
    "    examples=[\n",
    "        \"CI/CD is as crucial in AI systems as in traditional software. #mlops #cicd\",\n",
    "        \"Without test coverage for your data pipelines, you're flying blind.\",\n",
    "        \"Monitoring drift isn't a nice-to-have anymore. It's operational hygiene.\"\n",
    "    ]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2381af74-5627-41a4-a7e8-269bf89e0b37",
   "metadata": {},
   "source": [
    "### üìÑ Preview the Tweet Template\n",
    "\n",
    "We can inspect the automatically prepared prompt template that will be used to guide generation of each tweet.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa4e5ef-3de0-420d-b810-1120780c6424",
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_generator.prepared_sample_template"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1c09a4-304c-4d75-aa6e-2256c4474606",
   "metadata": {},
   "source": [
    "### ‚ú® Generate the Tweets\n",
    "\n",
    "Now we trigger the generation of new Twitter posts based on our few-shot prompt and user profile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ec9bca7614a4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_generator.generate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6b9672894160ac",
   "metadata": {},
   "source": [
    "### üîÑ Changing the LLM Provider\n",
    "\n",
    "By default, the generators use **OpenAI** models.\n",
    "You can also override this behavior by specifying a different `provider`, `model`, and the corresponding `options`. This makes it easy to experiment with multiple LLM providers without changing your generation logic ‚Äî simply swap the configuration while keeping the rest of the code the same.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef2070f6eaa7a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from evidently.llm.options import AnthropicOptions\n",
    "\n",
    "anthropic_api_key = os.environ.get(\"ANTHROPIC_API_KEY\", \"<put your key in env or here>\")\n",
    "options = AnthropicOptions(api_key=anthropic_api_key)\n",
    "\n",
    "twitter_generator = FewShotDatasetGenerator(\n",
    "    kind='twitter posts',\n",
    "    count=2,\n",
    "    user=UserProfile(\n",
    "        role=\"ML engineer\",\n",
    "        intent=\"user is trying to promote Evidently AI opensource library for llm chatbot testing\",\n",
    "        tone=\"confident\"),\n",
    "    complexity=\"medium\",\n",
    "    examples=[\n",
    "        \"CI/CD is as crucial in AI systems as in traditional software. #mlops #cicd\",\n",
    "        \"Without test coverage for your data pipelines, you're flying blind.\",\n",
    "        \"Monitoring drift isn't a nice-to-have anymore. It's operational hygiene.\"\n",
    "    ],\n",
    "    provider=\"anthropic\",\n",
    "    model=\"claude-sonnet-4-0\",\n",
    "    options=options\n",
    ")\n",
    "twitter_generator.generate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adaedde0fd53f605",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### üß† Example 2: RAG-Based Generation for Test User Queries\n",
    "\n",
    "In this section, we‚Äôll demonstrate how to use a small knowledge base file and the `RagDatasetGenerator` to generate user questions that an LLM could ask, simulating interaction with a booking website.\n",
    "\n",
    "---\n",
    "\n",
    "### üìö Prepare a Sample Knowledge Base\n",
    "\n",
    "We create a tiny knowledge base that will serve as our source of information for the RAG-based generation. In real scenarios, this could be a product FAQ, policy document, or knowledge article.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2e491bba462dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will use this single text as knowledge base. you can use your own files\n",
    "example_knowledge_base = \"\"\"Knowledge Base Entry: Hotel Booking Policies and Procedures\n",
    "\n",
    "Hotels generally offer two types of booking rates: refundable and non-refundable. Refundable rates allow cancellations or modifications up to 24‚Äì48 hours before check-in with no charge, making them ideal for travelers with uncertain plans. Non-refundable rates are typically lower in price but carry a cancellation fee or no refund at all if changes are made.\n",
    "\n",
    "Check-in time usually begins around 2:00 PM to 3:00 PM, and check-out is expected by 11:00 AM or 12:00 PM. Guests requesting early check-in or late check-out should contact the hotel in advance, as these options may involve additional fees and depend on room availability.\n",
    "\n",
    "Upon arrival, guests are required to present a valid government-issued photo ID and a credit or debit card. Some hotels may also request a security deposit, which is refundable upon check-out if no damage or extra charges are incurred.\n",
    "\n",
    "Payment policies vary: for prepaid bookings, the total amount may be charged at the time of reservation, especially for discounted or promotional rates. In other cases, payment is collected at the property during check-in or check-out.\n",
    "\n",
    "Special requests, such as extra beds, cribs, connecting rooms, allergy-friendly accommodations, or pet-friendly rooms, should be submitted at the time of booking. These are not guaranteed and must be confirmed by the hotel directly.\n",
    "\n",
    "Some hotels provide complimentary services like Wi-Fi, breakfast, or parking, while others charge extra. Guests should carefully review amenities, location details, and cancellation terms before finalizing the reservation.\"\"\"\n",
    "\n",
    "with open(\"booking_kb.txt\", \"w\") as f:\n",
    "    f.write(example_knowledge_base)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1193491f-4a6f-4415-92f0-5eaf6384a039",
   "metadata": {},
   "source": [
    "\n",
    "### üîç Initialize the RAG Generator\n",
    "\n",
    "We load the knowledge base and initialize the `RagDatasetGenerator` with user intent and context. This will generate realistic user queries that reference the provided information.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390d2e21a1f77525",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evidently.llm.datagen import RagDatasetGenerator\n",
    "from evidently.llm.rag.index import FileDataCollectionProvider\n",
    "\n",
    "data = FileDataCollectionProvider(path=\"booking_kb.txt\")\n",
    "booking_rag = RagDatasetGenerator(\n",
    "    data,\n",
    "    count=2,\n",
    "    include_context=False,\n",
    "    user=UserProfile(intent=\"get to know system\", role=\"new user\"),\n",
    "    service=\"booking website\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94304bd3-ba57-4442-8989-7ac0d5237d6a",
   "metadata": {},
   "source": [
    "\n",
    "### üìÑ View the Prepared Templates\n",
    "\n",
    "This shows how the generator structures prompts to generate questions from the knowledge base.\n",
    "\n",
    "Next, we look at the structure used to generate LLM responses to the generated queries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fdbb5bf-d81b-4ab5-b85a-e5e245c936f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "booking_rag.prepared_query_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85972fb6ad6ed1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "booking_rag.prepared_response_template"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef095f9-7720-4bfe-ac08-bd0d94e7eda7",
   "metadata": {},
   "source": [
    "### üíæ Export the Generation Configuration\n",
    "\n",
    "We export the generation setup to a YAML file so that it can be reused, shared, or version-controlled.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaaef266d2de3df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "booking_rag.dump(\"booking_rag.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f749b1c8-7ab7-4c97-a2fa-c2607642905a",
   "metadata": {},
   "source": [
    "### üßæ Review the YAML File\n",
    "\n",
    "We check the contents of the generated YAML spec for transparency and reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983fb6da249a999d",
   "metadata": {},
   "outputs": [],
   "source": [
    "! cat booking_rag.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a6171a-602f-435a-900c-44f10e1052ff",
   "metadata": {},
   "source": [
    "\n",
    "### üì¶ Load From YAML and Generate Data\n",
    "\n",
    "We load the generation spec from file and run the actual query/response generation pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b572a170b1ff8d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "booking_rag = RagDatasetGenerator.load(\"booking_rag.yaml\")\n",
    "booking_rag.generate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7821866e67f96",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### üß¨ Example 3: Custom RAG-Based Generation for Code Reviews\n",
    "\n",
    "In this example, we‚Äôll generate synthetic code diffs from the Evidently codebase and then simulate realistic code review comments for those diffs.\n",
    "\n",
    "---\n",
    "\n",
    "### üìÅ Load Python Files as Knowledge Base\n",
    "\n",
    "We use `FileDataCollectionProvider` to treat Evidently's source `.py` files as a corpus from which we can extract diffs.\n",
    "\n",
    "### üßæ Generate Git Diffs\n",
    "\n",
    "We use a RAG query generator configured to simulate `git diff` entries from the codebase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269da830242d1c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from evidently.llm.datagen import RagQueryDatasetGenerator, GenerationSpec\n",
    "import evidently\n",
    "\n",
    "data = FileDataCollectionProvider(path=os.path.dirname(evidently.__file__), recursive=True, pattern=\"*.py\")\n",
    "\n",
    "diff_generator = RagQueryDatasetGenerator(\n",
    "    data,\n",
    "    count=2,\n",
    "    chunks_per_query=1,\n",
    "    query_spec=GenerationSpec(kind=\"git diff\"),\n",
    ")\n",
    "diff_generator.prepared_query_template\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865faf90279a1771",
   "metadata": {},
   "outputs": [],
   "source": [
    "git_diffs = diff_generator.generate()\n",
    "git_diffs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9451ab1e-e15d-406f-8ec4-5725bfdf3885",
   "metadata": {},
   "source": [
    "\n",
    "### üß™ Inspect a Generated Git Diff\n",
    "\n",
    "Let‚Äôs preview one of the generated synthetic diffs that the model will review.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9617b117f886c279",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(git_diffs[\"queries\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32952f42-70bb-4ed2-9828-13055c762dee",
   "metadata": {},
   "source": [
    "### üß† Generate Code Reviews for Diffs\n",
    "\n",
    "We now pass the synthetic diffs into a new response generator, which produces simulated code review comments using a custom `code review` response spec."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ed63b52d07eb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from evidently.llm.datagen import RagResponseDatasetGenerator\n",
    "\n",
    "code_review_generator = RagResponseDatasetGenerator(\n",
    "    data,\n",
    "    query_spec=diff_generator.query_spec,\n",
    "    response_spec=GenerationSpec(kind=\"code review\"),\n",
    "    queries=list(git_diffs[\"queries\"]),\n",
    ")\n",
    "code_review_generator.prepared_response_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1eb5d16ac24841",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_review_generator.generate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fbc6dd2d10942d7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### ü§ñ Example 4: Custom Personal Assistant Data with Template Blocks\n",
    "\n",
    "In this final example, we explore full customization ‚Äî including custom prompt templates, prompt blocks, and user-defined generation specs.\n",
    "\n",
    "---\n",
    "\n",
    "### üß± Define Custom Prompt Block\n",
    "\n",
    "We create a fun prompt block that adds flavor to responses by appealing to the user‚Äôs mother. This demonstrates how to inject specific motivations, tones, or structural elements into generated prompts.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e39ea0075c945b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evidently.llm.utils.blocks import PromptBlock\n",
    "\n",
    "class MotherIncentiveBlock(PromptBlock):\n",
    "    \"\"\"If you perform {performance}, your mother will be {emotion} with you and give you {reward}.\"\"\"\n",
    "    performance: str\n",
    "    emotion: str\n",
    "    reward: str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0315a6-3998-4423-a9ef-3f30971a3a86",
   "metadata": {},
   "source": [
    "### üß† Build a Fully Custom RAG Generator\n",
    "\n",
    "We define a personal assistant service with user queries and AI responses, using custom templates and additional prompt blocks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd75e10fe5b710e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evidently.llm.datagen import ServiceSpec\n",
    "from evidently.llm.rag.index import ChunksDataCollectionProvider\n",
    "\n",
    "data = ChunksDataCollectionProvider(chunks=[\n",
    "        \"this AI personal assistant can help book things, set up reminders, answer stupid emails\"\n",
    "    ])\n",
    "\n",
    "my_template = \"\"\"\n",
    "    Please answer in style of Darth Vader\n",
    "\n",
    "    {% super() %}\n",
    "\"\"\"\n",
    "\n",
    "pa_generator = RagDatasetGenerator(\n",
    "    data,\n",
    "    count=2,\n",
    "    query_spec=GenerationSpec(kind=\"user requests\"),\n",
    "    response_spec=GenerationSpec(kind=\"AI Personal Assistant responses\"),\n",
    "    query_template=my_template,\n",
    "    response_template=my_template,\n",
    "    additional_prompt_blocks=[\n",
    "      MotherIncentiveBlock(performance=\"good\", emotion=\"pleased\", reward=\"10$\"),\n",
    "      MotherIncentiveBlock(performance=\"bad\", emotion=\"displeased\", reward=\"condescending look\"),\n",
    "    ],\n",
    "    service=ServiceSpec(kind=\"AI Personal Assistant\", purpose=\"help user solve simple tasks\"),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220f75e6-8410-4aa8-b1ee-c97316027916",
   "metadata": {},
   "source": [
    "### üìÑ View Custom Templates\n",
    "\n",
    "Let‚Äôs check how the query prompt looks with the Darth Vader theme and our mother-incentive block added.\n",
    "\n",
    "Similarly, we inspect how the assistant‚Äôs response prompt is structured using the custom blocks.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3445e3-4863-4963-92cf-6990d05c11d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pa_generator.prepared_query_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb9b7cd0c636cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "pa_generator.prepared_response_template"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2745bf-c8e8-48a4-a7ff-5f91c983a2cf",
   "metadata": {},
   "source": [
    "### ‚ú® Generate PA Queries and Responses\n",
    "\n",
    "Finally, we run the generator to produce synthetic queries and AI responses using our fully customized setup.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8788ab8e9dbbcd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pa_queries = pa_generator.generate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbfacfa8-836e-4a1e-b35e-696cc66a581c",
   "metadata": {},
   "source": [
    "\n",
    "### üì¶ View the Output\n",
    "\n",
    "We preview the generated examples from our personal assistant scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0cea63afd2c8721",
   "metadata": {},
   "outputs": [],
   "source": [
    "pa_queries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977806da51faa413",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### ‚úÖ Summary: What We Learned\n",
    "\n",
    "In this tutorial, we explored the capabilities of the new `evidently.llm.datagen` API for generating high-quality synthetic datasets for testing and evaluation of LLM systems. Here's a recap of the key concepts and tools demonstrated:\n",
    "\n",
    "#### üß™ Dataset Generators\n",
    "\n",
    "* **FewShotDatasetGenerator**: Allows generation based on a few manual examples and a user profile. Ideal for generating social media content, slogans, or short texts.\n",
    "* **RagDatasetGenerator**: Enables generation grounded in a knowledge base, supporting realistic question/answer generation from documents or FAQs.\n",
    "* **RagQueryDatasetGenerator / RagResponseDatasetGenerator**: Allow fine-grained control over multi-stage generation workflows, such as producing diffs and corresponding code reviews.\n",
    "\n",
    "#### üß© Core Building Blocks\n",
    "\n",
    "* **UserProfile and ServiceSpec**: Provide structured user and service descriptions to simulate realistic scenarios.\n",
    "* **GenerationSpec**: Lets you define the kind of content to generate (e.g., `\"git diff\"`, `\"code review\"`, `\"AI assistant responses\"`).\n",
    "* **PromptBlock**: Enables reusable components to structure prompts, inject motivations, or define response tone and format.\n",
    "* **Templates**: Custom Jinja-style templates can be used to control prompt layout and stylistic constraints.\n",
    "\n",
    "#### üîß Use Cases Covered\n",
    "\n",
    "* Creating LLM-ready Twitter datasets with domain knowledge and tone control.\n",
    "* Simulating RAG-style user queries and chatbot responses from a knowledge base.\n",
    "* Generating synthetic developer workflows like diffs and reviews using real code.\n",
    "* Building end-to-end assistant datasets with templated queries, responses, and structured prompt blocks.\n",
    "\n",
    "This API gives you composable building blocks for generating test data tailored to your product, domain, and evaluation needs. Whether you‚Äôre testing chatbot robustness, fine-tuning with synthetic data, or building eval suites for new LLM apps ‚Äî `evidently.llm.datagen` provides a flexible, inspectable foundation to start from.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9970992b-2b46-46b5-9430-24c559e46b06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
