{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jn4VjbRSEm8L",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import evidently\n",
    "except:\n",
    "    !npm install -g yarn\n",
    "    !pip install git+https://github.com/evidentlyai/evidently.git@test_suite_alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zGBzUG6ThEU_",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Data Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HoDiwl7TLI_U",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from evidently.test_suite import TestSuite\n",
    "\n",
    "from evidently.tests import TestFeatureValueMin, TestFeatureValueMax, TestFeatureValueMean, \\\n",
    "TestFeatureValueMedian, TestFeatureValueStd,\\\n",
    "TestMeanInNSigmas, TestValueRange, TestNumberOfOutRangeValues, TestShareOfOutRangeValues, TestValueList, \\\n",
    "TestNumberOfOutListValues, TestShareOfOutListValues, TestNumberOfUniqueValues, TestMostCommonValueShare, \\\n",
    "TestUniqueValuesShare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lMozc2f4hJiN",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from evidently import ColumnMapping\n",
    "from datetime import datetime\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "data = fetch_openml(name='adult', version=2, as_frame='auto')\n",
    "df = data.frame\n",
    "\n",
    "ref = df[~df.education.isin(['Some-college', 'HS-grad', 'Bachelors'])]\n",
    "curr = df[df.education.isin(['Some-college', 'HS-grad', 'Bachelors'])]\n",
    "\n",
    "curr.iloc[:2000, 3:5] = np.nan\n",
    "curr.iloc[:2000, 12] = np.nan\n",
    "\n",
    "suite_with_ref = TestSuite(tests=[\n",
    "TestFeatureValueMin(column_name='hours-per-week'),\n",
    "TestFeatureValueMax(column_name='hours-per-week'),\n",
    "TestFeatureValueMean(column_name='hours-per-week'),\n",
    "TestFeatureValueMedian(column_name='hours-per-week'),\n",
    "TestFeatureValueStd(column_name='hours-per-week'),\n",
    "TestMeanInNSigmas(column_name='hours-per-week'),\n",
    "TestValueRange(column_name='hours-per-week'),\n",
    "TestNumberOfOutRangeValues(column_name='hours-per-week'),\n",
    "TestShareOfOutRangeValues(column_name='hours-per-week'),\n",
    "TestValueList(column_name='education'),\n",
    "TestNumberOfOutListValues(column_name='hours-per-week'),\n",
    "TestShareOfOutListValues(column_name='education'),\n",
    "TestNumberOfUniqueValues(column_name='hours-per-week'),\n",
    "TestMostCommonValueShare(column_name='education'),\n",
    "TestUniqueValuesShare(column_name='education')\n",
    "    ])\n",
    "suite_with_ref.run(reference_data=ref,\n",
    "          current_data=curr, column_mapping=ColumnMapping())\n",
    "suite_with_ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6bY8ky-6hShC",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "suite = TestSuite(tests=[\n",
    "TestFeatureValueMin(column_name='hours-per-week'),\n",
    "TestFeatureValueMax(column_name='hours-per-week'),\n",
    "TestFeatureValueMean(column_name='hours-per-week'),\n",
    "TestFeatureValueMedian(column_name='hours-per-week'),\n",
    "TestFeatureValueStd(column_name='hours-per-week'),\n",
    "# TestMeanInNSigmas(column_name='hours-per-week'),\n",
    "TestValueRange(column_name='hours-per-week', left=7, right=13),\n",
    "TestNumberOfOutRangeValues(column_name='hours-per-week', left=3, right=5),\n",
    "TestShareOfOutRangeValues(column_name='hours-per-week', left=3, right=5),\n",
    "TestValueList(column_name='education', values=['HS-grad', 'Bachelors']),\n",
    "TestNumberOfOutListValues(column_name='hours-per-week', values=['HS-grad', 'Bachelors']),\n",
    "TestShareOfOutListValues(column_name='education', values=['HS-grad', 'Bachelors']),\n",
    "TestNumberOfUniqueValues(column_name='hours-per-week'),\n",
    "TestMostCommonValueShare(column_name='education'),\n",
    "TestUniqueValuesShare(column_name='education')\n",
    "    ])\n",
    "suite.run(reference_data=ref,\n",
    "          current_data=curr, column_mapping=ColumnMapping())\n",
    "suite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eTqsXV_chVno",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Data Drift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ODvJ8xdwhXgo",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from evidently.test_suite import TestSuite\n",
    "\n",
    "from evidently.tests import TestShareOfDriftedFeatures, TestFeatureValueDrift, TestNumberOfDriftedFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dM-3lZcThaM_",
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from evidently import ColumnMapping\n",
    "from datetime import datetime\n",
    "from sklearn.datasets import fetch_openml\n",
    "from evidently.test_preset import NoTargetPerformance, DataQuality, DataStability, DataDrift\n",
    "\n",
    "data = fetch_openml(name='adult', version=2, as_frame='auto')\n",
    "df = data.frame\n",
    "\n",
    "ref = df[~df.education.isin(['Some-college', 'HS-grad', 'Bachelors'])]\n",
    "curr = df[df.education.isin(['Some-college', 'HS-grad', 'Bachelors'])]\n",
    "\n",
    "curr['target'] = curr['education-num']\n",
    "curr['preds'] = curr['education-num'].values + np.random.normal(0, 6, curr.shape[0])\n",
    "ref['target'] = ref['education-num']\n",
    "ref['preds'] = ref['education-num'].values + np.random.normal(0, 6, ref.shape[0])\n",
    "\n",
    "curr.iloc[:2000, 3:5] = np.nan\n",
    "curr.iloc[:2000, 12] = np.nan\n",
    "\n",
    "suite = TestSuite(tests=[\n",
    "    TestShareOfDriftedFeatures(),\n",
    "    TestNumberOfDriftedFeatures(),\n",
    "    TestFeatureValueDrift(column_name='education-num'),\n",
    "    TestFeatureValueDrift(column_name='education')\n",
    "])\n",
    "\n",
    "suite.run(reference_data=ref,\n",
    "          current_data=curr, column_mapping=ColumnMapping(target='target', prediction='preds'))\n",
    "suite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Test Preset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "suite = TestSuite(tests=[\n",
    "    NoTargetPerformance(most_important_features=[\"education-num\"]),\n",
    "])\n",
    "\n",
    "suite.run(reference_data=ref,\n",
    "          current_data=curr, column_mapping=ColumnMapping(target='target', prediction='preds'))\n",
    "suite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "suite = TestSuite(tests=[\n",
    "    DataDrift(),\n",
    "])\n",
    "\n",
    "suite.run(reference_data=ref,\n",
    "          current_data=curr, column_mapping=ColumnMapping(target='target', prediction='preds'))\n",
    "suite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "suite = TestSuite(tests=[\n",
    "    DataStability(),\n",
    "])\n",
    "\n",
    "suite.run(reference_data=ref,\n",
    "          current_data=curr, column_mapping=ColumnMapping(target='target', prediction='preds'))\n",
    "suite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "suite = TestSuite(tests=[\n",
    "    DataQuality(),\n",
    "])\n",
    "\n",
    "suite.run(reference_data=ref,\n",
    "          current_data=curr, column_mapping=ColumnMapping(target='target', prediction='preds'))\n",
    "suite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YYngaSamherk",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cYuWgVhPhfDV",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from evidently.test_suite import TestSuite\n",
    "\n",
    "from evidently.tests import TestValueMAE, TestValueRMSE, TestValueMeanError, TestValueMAPE, \\\n",
    "TestValueAbsMaxError, TestValueR2Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BBTIPLbZhhwH",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from evidently import ColumnMapping\n",
    "from datetime import datetime\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "data = fetch_openml(name='adult', version=2, as_frame='auto')\n",
    "df = data.frame\n",
    "\n",
    "ref = df[:20000]\n",
    "curr = df[20000:]\n",
    "\n",
    "curr['target'] = curr['education-num']\n",
    "curr['preds'] = curr['education-num'].values + np.random.normal(0, 6, curr.shape[0])\n",
    "ref['target'] = ref['education-num']\n",
    "ref['preds'] = ref['education-num'].values + np.random.normal(0, 6, ref.shape[0])\n",
    "\n",
    "curr.iloc[:2000, 3:5] = np.nan\n",
    "curr.iloc[:2000, 12] = np.nan\n",
    "\n",
    "suite = TestSuite(tests=[\n",
    "    TestValueMAE(),\n",
    "    TestValueRMSE(),\n",
    "    TestValueMeanError(),\n",
    "    TestValueMAPE(),\n",
    "    TestValueAbsMaxError(),\n",
    "    TestValueR2Score()\n",
    "])\n",
    "\n",
    "suite.run(reference_data=ref,\n",
    "          current_data=curr, column_mapping=ColumnMapping(target='target', prediction='preds'))\n",
    "suite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from evidently import ColumnMapping\n",
    "from datetime import datetime\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "data = fetch_openml(name='adult', version=2, as_frame='auto')\n",
    "df = data.frame\n",
    "\n",
    "ref = df[:20000]\n",
    "curr = df[20000:]\n",
    "\n",
    "curr['target'] = curr['education-num']\n",
    "curr['preds'] = curr['education-num'].values + np.random.normal(0, 6, curr.shape[0])\n",
    "ref['target'] = ref['education-num']\n",
    "ref['preds'] = ref['education-num'].values + np.random.normal(0, 6, ref.shape[0])\n",
    "\n",
    "curr.iloc[:2000, 3:5] = np.nan\n",
    "curr.iloc[:2000, 12] = np.nan\n",
    "\n",
    "suite = TestSuite(tests=[\n",
    "    TestValueMAE(),\n",
    "    TestValueRMSE(),\n",
    "    TestValueMeanError(),\n",
    "    TestValueMAPE(),\n",
    "    TestValueAbsMaxError(),\n",
    "    TestValueR2Score()\n",
    "])\n",
    "\n",
    "suite.run(reference_data=None,\n",
    "          current_data=curr, column_mapping=ColumnMapping(target='target', prediction='preds'))\n",
    "suite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Test Generators\n",
    "If you want to create a list of tests, you can just use a list comprehension.\n",
    "As an example we create tests for quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "from evidently.tests import TestValueQuantile\n",
    "from evidently.test_suite import TestSuite\n",
    "\n",
    "\n",
    "data = fetch_openml(name='adult', version=2, as_frame='auto')\n",
    "df = data.frame\n",
    "ref = df[:20000]\n",
    "curr = df[20000:]\n",
    "\n",
    "\n",
    "suite = TestSuite(tests=[\n",
    "    TestValueQuantile(column_name=\"education-num\", quantile=quantile) for quantile in [0.5, 0.9, 0.99]\n",
    "])\n",
    "\n",
    "suite.run(reference_data=ref, current_data=curr)\n",
    "suite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "But if you want to use column names in tests generation, you can get it after the suite calculation is already launched.\n",
    "\n",
    "In this case you can make a test generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "from evidently.analyzers.utils import DatasetColumns\n",
    "from evidently.tests.base_test import BaseTestGenerator\n",
    "from evidently.tests import TestValueQuantile\n",
    "from evidently.test_suite import TestSuite\n",
    "\n",
    "\n",
    "data = fetch_openml(name='adult', version=2, as_frame='auto')\n",
    "df = data.frame\n",
    "\n",
    "ref = df[:20000]\n",
    "curr = df[20000:]\n",
    "\n",
    "\n",
    "class TestAllQuantiles(BaseTestGenerator):\n",
    "        def generate_tests(self, columns_info: DatasetColumns) -> List[TestValueQuantile]:\n",
    "            # iterate over all numeric features\n",
    "            return [\n",
    "                TestValueQuantile(column_name=name, quantile=quantile)\n",
    "                for quantile in (0.5, 0.9, 0.99)\n",
    "                for name in columns_info.num_feature_names\n",
    "            ]\n",
    "\n",
    "suite = TestSuite(tests=[TestAllQuantiles()])\n",
    "suite.run(reference_data=ref, current_data=curr)\n",
    "suite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alos you can use pre-defined test generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "from evidently.test_suite import TestSuite\n",
    "from evidently.tests.base_test import generate_tests_for_columns\n",
    "from evidently.tests.base_test import generate_tests_for_all_columns\n",
    "from evidently.tests.base_test import generate_tests_for_num_features\n",
    "from evidently.tests.base_test import generate_tests_for_cat_features\n",
    "from evidently.tests.base_test import generate_tests_for_datetime_features\n",
    "from evidently.tests import TestFeatureValueMin\n",
    "from evidently.tests import TestColumnNANShare\n",
    "from evidently.tests import TestColumnAllUniqueValues\n",
    "\n",
    "data = fetch_openml(name='adult', version=2, as_frame='auto')\n",
    "df = data.frame\n",
    "\n",
    "ref = df[:20000]\n",
    "curr = df[20000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use **generate_tests_for_columns** if you want to generate tests for a custom list of columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suite = TestSuite(tests=[generate_tests_for_columns(TestColumnNANShare, columns=[\"age\", \"workclass\", \"race\"])])\n",
    "suite.run(current_data=curr, reference_data=ref)\n",
    "suite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use **generate_tests_for_all_columns** if you want to generate tests for all columns, include **target** and **prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suite = TestSuite(tests=[generate_tests_for_all_columns(TestColumnNANShare, per_column_parameters={\n",
    "    \"fnlwgt\": {\n",
    "        \"gt\": 0.7\n",
    "    }\n",
    "})])\n",
    "suite.run(current_data=curr, reference_data=ref)\n",
    "suite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the same for numeric, category and datetime features, exclude special columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suite = TestSuite(tests=[generate_tests_for_num_features(TestFeatureValueMin, for_all_parameters={\n",
    "    \"gt\": 0.7\n",
    "})])\n",
    "suite.run(current_data=curr, reference_data=ref)\n",
    "suite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suite = TestSuite(tests=[generate_tests_for_cat_features(TestColumnAllUniqueValues)])\n",
    "suite.run(current_data=curr, reference_data=ref)\n",
    "suite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suite = TestSuite(tests=[generate_tests_for_datetime_features(TestColumnAllUniqueValues)])\n",
    "suite.run(current_data=curr, reference_data=ref)\n",
    "suite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "example_tests.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
