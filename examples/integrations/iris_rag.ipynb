{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iris Vector Database RAG Integration with Evidently\n",
    "\n",
    "This notebook demonstrates how to use InterSystems IRIS as a vector database for RAG (Retrieval-Augmented Generation) with Evidently's LLM evaluation capabilities.\n",
    "\n",
    "## Overview\n",
    "\n",
    "We'll cover:\n",
    "1. Setting up IRIS vector database with sample data\n",
    "2. Using Evidently's RAG module with IRIS backend\n",
    "3. Performing similarity searches and evaluations\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- IRIS instance running locally (Docker recommended)\n",
    "- Python packages: `intersystems-irispython`, `evidently[llm,iris]`, `sentence-transformers`"
   ],
   "id": "1b79cd212da85e56"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Install Required Packages"
   ],
   "id": "f21d942d9a0f5620"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Install required packages\n",
    "# ! pip install intersystems-irispython evidently[llm,iris] sentence-transformers"
   ],
   "id": "61711a794d05929b",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Setup IRIS Vector Database\n",
    "\n",
    "First, we'll connect to IRIS and create a vector table with sample data."
   ],
   "id": "d87bb14630ebbee"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import iris\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# IRIS connection parameters\n",
    "username = 'SuperUser'\n",
    "password = ''\n",
    "hostname = 'localhost'\n",
    "port = 1972\n",
    "namespace = 'USER'\n",
    "\n",
    "# Create connection string\n",
    "connection_string = f\"{hostname}:{port}/{namespace}\"\n",
    "\n",
    "# Connect to IRIS\n",
    "connection = iris.connect(connection_string, username, password)\n",
    "cursor = connection.cursor()\n",
    "\n",
    "print(f\"Connected to IRIS at {connection_string}\")"
   ],
   "id": "f062a7c70550fd0f",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Create vector table for our RAG data\n",
    "table_name = \"evidently_rag_demo\"\n",
    "table_definition = \"\"\"(\n",
    "    ID INT PRIMARY KEY,\n",
    "    text VARCHAR(2000),\n",
    "    vector_data VECTOR(FLOAT, 384),\n",
    "    source VARCHAR(200)\n",
    ")\"\"\"\n",
    "\n",
    "# Drop table if exists and recreate\n",
    "try:\n",
    "    cursor.execute(f\"DROP TABLE {table_name}\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "cursor.execute(f\"CREATE TABLE {table_name} {table_definition}\")\n",
    "print(f\"Created table: {table_name}\")"
   ],
   "id": "28e6e1a1036fb2f6",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Sample documents for our RAG system\n",
    "sample_documents = [\n",
    "    {\n",
    "        \"text\": \"Machine learning is a subset of artificial intelligence that focuses on algorithms that can learn from data without being explicitly programmed.\",\n",
    "        \"source\": \"ml_basics.txt\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"Deep learning uses neural networks with multiple layers to model and understand complex patterns in data. It's particularly effective for image recognition and natural language processing.\",\n",
    "        \"source\": \"deep_learning.txt\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"Natural language processing (NLP) enables computers to understand, interpret, and generate human language. It's used in chatbots, translation, and sentiment analysis.\",\n",
    "        \"source\": \"nlp_intro.txt\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"Vector databases store and search high-dimensional vectors efficiently. They're essential for semantic search, recommendation systems, and RAG applications.\",\n",
    "        \"source\": \"vector_db.txt\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"Retrieval-Augmented Generation (RAG) combines information retrieval with language generation to provide more accurate and contextual responses.\",\n",
    "        \"source\": \"rag_concept.txt\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Initialize sentence transformer model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Insert documents with embeddings\n",
    "for i, doc in enumerate(sample_documents):\n",
    "    # Generate embedding\n",
    "    embedding = model.encode(doc['text']).tolist()\n",
    "    \n",
    "    # Insert into IRIS table\n",
    "    cursor.execute(\n",
    "        f\"INSERT INTO {table_name} (ID, text, vector_data, source) VALUES (?, ?, ?, ?)\",\n",
    "        [i + 1, doc['text'], str(embedding), doc['source']]\n",
    "    )\n",
    "\n",
    "connection.commit()\n",
    "print(f\"Inserted {len(sample_documents)} documents into {table_name}\")"
   ],
   "id": "bf81bb6006f3eeae",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Test Vector Search in IRIS\n",
    "\n",
    "Let's test the vector similarity search directly in IRIS before using Evidently."
   ],
   "id": "9a051b55031a268b"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Test vector similarity search\n",
    "query_text = \"What is machine learning and how does it work?\"\n",
    "query_vector = model.encode(query_text).tolist()\n",
    "\n",
    "# Perform similarity search\n",
    "search_sql = f\"\"\"\n",
    "SELECT TOP 3 ID, text, source\n",
    "FROM {table_name}\n",
    "ORDER BY VECTOR_DOT_PRODUCT(vector_data, ?) DESC\n",
    "\"\"\"\n",
    "\n",
    "cursor.execute(search_sql, [str(query_vector)])\n",
    "results = cursor.fetchall()\n",
    "\n",
    "print(f\"Query: {query_text}\")\n",
    "print(\"\\nMost relevant documents:\")\n",
    "for i, result in enumerate(results, 1):\n",
    "    print(f\"{i}. ID: {result[0]}, Source: {result[2]}\")\n",
    "    print(f\"   Text: {result[1]}\")\n",
    "    print()"
   ],
   "id": "2732b4e40eaf20f1",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Using Evidently RAG with IRIS\n",
    "\n",
    "Now let's use Evidently's RAG module with our IRIS vector database using the new flat parameter API."
   ],
   "id": "b28d9638130406e8"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from evidently.llm.rag.iris_index import IrisDataCollectionProvider\n",
    "from evidently.llm.rag.splitter import Chunk\n",
    "\n",
    "# Create IRIS data collection provider with flat parameters\n",
    "iris_provider = IrisDataCollectionProvider(\n",
    "    # Connection parameters (all required except port)\n",
    "    hostname=hostname,\n",
    "    port=port,  # defaults to 1972 if not specified\n",
    "    namespace=namespace,\n",
    "    username=username,\n",
    "    password=password,\n",
    "    # Table configuration\n",
    "    table_name=table_name,\n",
    "    text_column=\"text\",\n",
    "    vector_column=\"vector_data\",\n",
    "    id_column=\"ID\"\n",
    ")\n",
    "\n",
    "print(\"Created IRIS data collection provider with flat parameters\")"
   ],
   "id": "8ae92cf727a858d5",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Get the data collection and test it\n",
    "data_collection = iris_provider.get_data_collection()\n",
    "\n",
    "# Test queries\n",
    "test_queries = [\n",
    "    \"What is machine learning?\",\n",
    "    \"How do neural networks work?\",\n",
    "    \"What is RAG and why is it useful?\",\n",
    "    \"Tell me about vector databases\"\n",
    "]\n",
    "\n",
    "for query in test_queries:\n",
    "    print(f\"\\nQuery: {query}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Find relevant chunks\n",
    "    relevant_chunks = data_collection.find_relevant_chunks(query, n_results=2)\n",
    "    \n",
    "    for i, chunk in enumerate(relevant_chunks, 1):\n",
    "        print(f\"{i}. {chunk}\")\n",
    "        print()"
   ],
   "id": "7b7d0812d80ad2d2",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: RAG Dataset Generation\n",
    "\n",
    "Now let's use Evidently's RAG dataset generation capabilities with our IRIS backend."
   ],
   "id": "524cbbafaa7e56f3"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from evidently.llm.datagen.rag import RagDatasetGenerator\n",
    "from evidently.llm.datagen.config import GenerationSpec\n",
    "\n",
    "# Create RAG dataset generator using our IRIS provider\n",
    "rag_generator = RagDatasetGenerator(\n",
    "    data_collection=iris_provider,\n",
    "    count=5,  # Generate 5 question-answer pairs\n",
    "    model=\"gpt-4o-mini\",\n",
    "    provider=\"openai\",\n",
    "    query_spec=GenerationSpec(kind=\"question\", complexity=\"medium\"),\n",
    "    response_spec=GenerationSpec(kind=\"answer\", complexity=\"medium\")\n",
    ")\n",
    "\n",
    "print(\"Created RAG dataset generator with IRIS backend\")"
   ],
   "id": "d4d5d17846180742",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Generate dataset (requires OpenAI API key)\n",
    "import os\n",
    "\n",
    "# Note: You'll need to set your OpenAI API key\n",
    "# os.environ['OPENAI_API_KEY'] = 'your-api-key-here'\n",
    "\n",
    "dataset_result = rag_generator.generate()\n",
    "\n",
    "print(f\"Generated {len(dataset_result)} question-answer pairs\")\n",
    "for i, gen in dataset_result.iterrows():\n",
    "    print(f\"\\n{i+1}. Question: {gen[0]}\")\n",
    "    print(f\"   Answer: {gen[1]}\")\n",
    "\n",
    "print(\"RAG dataset generation ready (requires OpenAI API key)\")"
   ],
   "id": "e8b68970aa6059e9",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Cleanup and Best Practices\n",
    "\n",
    "Let's clean up our resources and discuss best practices."
   ],
   "id": "d05d4028899b8d14"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Cleanup: Close connections\n",
    "if 'data_collection' in locals():\n",
    "    data_collection.close()\n",
    "\n",
    "if 'connection' in locals():\n",
    "    connection.close()\n",
    "\n",
    "print(\"Closed all database connections\")"
   ],
   "id": "19d8d736290cec23",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Best Practices\n",
    "\n",
    "### What We've Accomplished:\n",
    "\n",
    "1. **IRIS Vector Database Setup**: Created a vector table and populated it with sample documents\n",
    "2. **Evidently Integration**: Used `IrisDataCollectionProvider` with flat parameters to integrate IRIS with Evidently's RAG system\n",
    "3. **Similarity Search**: Demonstrated vector similarity search using `VECTOR_DOT_PRODUCT`\n",
    "4. **RAG Dataset Generation**: Set up RAG dataset generation with IRIS backend\n",
    "\n",
    "### Key Features of the New API:\n",
    "\n",
    "1. **Flat Parameters**: The provider accepts connection parameters directly instead of a connection object\n",
    "2. **Required Parameters**: Most connection parameters are required (except port which defaults to 1972)\n",
    "3. **Type Safety**: Port is now an integer type\n",
    "4. **Connection Management**: `IrisConnection` handles cursor and connection management\n",
    "5. **Simplified Usage**: No need to create connection objects manually\n",
    "\n",
    "### Best Practices:\n",
    "\n",
    "1. **Connection Management**: Always close database connections when done\n",
    "2. **Error Handling**: Implement proper error handling for database operations\n",
    "3. **Indexing**: Consider creating indexes on frequently queried columns\n",
    "4. **Batch Operations**: Use batch inserts for large datasets\n",
    "5. **Monitoring**: Monitor query performance and optimize as needed\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "1. Set up your OpenAI API key to test dataset generation\n",
    "2. Experiment with different embedding models\n",
    "3. Try different similarity search functions (cosine, etc.)\n",
    "4. Implement batch document processing\n",
    "5. Add monitoring and logging for production use"
   ],
   "id": "b3f284078d26f0da"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
